<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://inlong.apache.org/zh-CN/blog</id>
    <title>Apache InLong Blog</title>
    <updated>2025-01-03T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://inlong.apache.org/zh-CN/blog"/>
    <subtitle>Apache InLong Blog</subtitle>
    <icon>https://inlong.apache.org/zh-CN/img/logo.svg</icon>
    <entry>
        <title type="html"><![CDATA[2.1.0 版本发布]]></title>
        <id>https://inlong.apache.org/zh-CN/blog/2025/01/03/release-2.1.0</id>
        <link href="https://inlong.apache.org/zh-CN/blog/2025/01/03/release-2.1.0"/>
        <updated>2025-01-03T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Apache InLong（应龙） 最近发布了 2.1.0 版本，该版本关闭了约 120+ 个 issue，包含 4+ 个大特性和 110+ 个优化，主要完成了 Dashboard 支持批量操作节点、Manager 支持多种调度引擎、Agent 支持 COS 数据源、Sort 支持通过 InLong SDK 进行脏数据的归档。同时优化 Apache InLong 运营运维的使用体验。Apache InLong 2.1.0 版本中，还完成了大量其它特性。]]></summary>
        <content type="html"><![CDATA[<p>Apache InLong（应龙） 最近发布了 2.1.0 版本，该版本关闭了约 120+ 个 issue，包含 4+ 个大特性和 110+ 个优化，主要完成了 Dashboard 支持批量操作节点、Manager 支持多种调度引擎、Agent 支持 COS 数据源、Sort 支持通过 InLong SDK 进行脏数据的归档。同时优化 Apache InLong 运营运维的使用体验。Apache InLong 2.1.0 版本中，还完成了大量其它特性。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="关于-apache-inlong">关于 Apache InLong<a href="#关于-apache-inlong" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>作为业界首个一站式、全场景海量数据集成框架，Apache InLong（应龙） 提供了自动、安全、可靠和高性能的数据传输能力，方便业务快速构建基于流式的数据分析、建模和应用。目前 InLong 正广泛应用于广告、支付、社交、游戏、人工智能等各个行业领域，服务上千个业务，其中高性能场景数据规模超百万亿条/天，高可靠场景数据规模超十万亿条/天。
InLong 项目定位的核心关键词是“一站式”、“全场景”和“海量数据”。对于“一站式”，我们希望屏蔽技术细节、提供完整数据集成及配套服务，实现开箱即用；对于“全场景”，我们希望提供全方位的解决方案，覆盖大数据领域常见的数据集成场景；对于“海量数据”，我们希望通过架构上的数据链路分层、全组件可扩展、自带多集群管理等优势，在百万亿条/天的基础上，稳定支持更大规模的数据量。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="210-版本总览">2.1.0 版本总览<a href="#210-版本总览" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>Apache InLong（应龙） 最近发布了 2.1.0 版本，该版本关闭了约 120+ 个 issue，包含 4+ 个大特性和 110+ 个优化，主要完成了</p><ul><li>Dashboard 支持批量操作节点</li><li>Manager 支持多种调度引擎</li><li>Agent 支持 COS 数据源</li><li>Sort 支持通过 InLong SDK 进行脏数据的归档。</li></ul><p>同时优化 Apache InLong 运营运维的使用体验。Apache InLong 2.1.0 版本中，还完成了大量其它特性。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dashboard-模块">Dashboard 模块<a href="#dashboard-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持 COS 数据源</li><li>支持 Agent 批量操作：重启、升级</li><li>支持审计数据导出成 CSV 文件</li><li>支持审计数据排序、差值对比</li><li>支持全量指标类型查询</li><li>支持数据预览字段分割</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-模块">Manager 模块<a href="#manager-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持 COS 数据源</li><li>支持管理多种调度引擎：AirFlow、DolphinScheduler</li><li>支持脏数据管理以及查询</li><li>支持根据 IP 查询心跳信息</li><li>限制一个 IP 只能归属到一个集群</li><li>提供脏数据归档查询 API</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-模块">Agent 模块<a href="#agent-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持 COS 数据源</li><li>支持快速启动、关闭</li><li>支持启动多实例</li><li>支持按时间顺序补录数据</li><li>优化 Installer 守护 Agent 逻辑</li><li>支持按照数据本地时间进行补录</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-模块">Sort 模块<a href="#sort-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>新增基于 Flink 1.18 的 Elasticsearch connector</li><li>支持 Kafka Sink 端的 KV 分隔</li><li>支持审计数据上报</li><li>Tube Connector source 支持脏数据归档</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sdk-模块">SDK 模块<a href="#sdk-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>Transform SDK 新增 7 种函数</li><li>新增脏数据归档 SDK</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="audit-模块">Audit 模块<a href="#audit-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>Audit Proxy 增加指标上报</li><li>Audit Store 增加指标上报</li><li>Audit Service 增加指标上报</li><li>新增异步刷审计数据接口</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="tubemq-模块">TubeMQ 模块<a href="#tubemq-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>将消费位点信息写到本地文件</li><li>优化 Go 版本 SDK 负载均衡逻辑</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="其他">其他<a href="#其他" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>流水线支持并行构建</li><li>支持管理器配置卷</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="210-版本主要特性">2.1.0 版本主要特性<a href="#210-版本主要特性" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dashboard-支持批量操作节点">Dashboard 支持批量操作节点<a href="#dashboard-支持批量操作节点" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>改特性主要是用于 Inlong Agent 的操作：主要是升级和重启：</p><ul><li><p>在集群管理找到集群后，选择要操作的多个节点，点击 批量操作。</p><p><img loading="lazy" alt="2.1.0-dashboard-select.png" src="/zh-CN/assets/images/2.1.0-dashboard-select-a3bfca0341cb5545ab0c6a966ad02271.png" width="2477" height="645" class="img_ev3q"></p></li><li><p>选择操作类型，并填写对应操作所需的参数，点击确定即可。</p><p><img loading="lazy" alt="2.1.0-dashboard-operate.png" src="/zh-CN/assets/images/2.1.0-dashboard-operate-3f6d28247a6fd0ddff55bc7a9c0249db.png" width="1478" height="1028" class="img_ev3q"></p></li></ul><p>该功能优化了 Inlong 的运维体验：界面化操作，运维不再需要操作 DB，增加了 Inlong 的内聚性：</p><ul><li>可视化 Agent 版本升级，可分批、定时升级，控制升级风险。</li><li>Agent 故障恢复时可通过该功能进行快速重启。</li></ul><p>感谢 @<a href="https://github.com/wohainilaodou" target="_blank" rel="noopener noreferrer">wohainilaodou</a> 的贡献，详情参考 <a href="https://github.com/apache/inlong/issues/11187" target="_blank" rel="noopener noreferrer">INLONG-11187</a></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-支持多种调度引擎">Manager 支持多种调度引擎<a href="#manager-支持多种调度引擎" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>之前对于离线数据同步 Inlong 只支持 Quartz 调度引擎。这次的版本则增加了两个第三方引擎：DolphinScheudler 和 AirFlow。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="airflow-引擎">AirFlow 引擎<a href="#airflow-引擎" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4><ul><li>为了便于未来 AirFlow 接口支持的维护和扩展，设计了 AirflowApi 接口和 BaseAirflowApi 抽象类，后续扩展只需要在此基础上进行。</li><li>为接口实现统一的请求类 AirflowServerClient。</li><li>在 OkHttpClient 中添加两个拦截器：AirflowAuthInterceptor 用于接口的统一授权；LoggingInterceptor 用于日志记录。</li></ul><p>感谢 @<a href="https://github.com/Zkplo" target="_blank" rel="noopener noreferrer">Zkplo</a> 的贡献，详情参考 <a href="https://github.com/apache/inlong/issues/11400" target="_blank" rel="noopener noreferrer">INLONG-11400</a></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="dolphinscheudler-引擎">DolphinScheudler 引擎<a href="#dolphinscheudler-引擎" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4><ul><li>在 org.apache.inlong.manager.schedule 中添加 DolphinScheudler 包</li><li>添加 DS 的客户端和引擎，以及用于操作 DS 的开放 API 的 Util</li><li>为 DS 交互添加 pojo 类</li></ul><p>感谢 @<a href="https://github.com/emptyOVO" target="_blank" rel="noopener noreferrer">emptyOVO</a> 的贡献，详情参考 <a href="https://github.com/apache/inlong/issues/11401" target="_blank" rel="noopener noreferrer">INLONG-11401</a></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-支持-cos-数据源">Agent 支持 COS 数据源<a href="#agent-支持-cos-数据源" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li><p>新建 COS 类型节点，填写相应的 桶名、凭据 ID、凭据密钥和地区即可。</p><p><img loading="lazy" alt="2.1.0-agent-node.png" src="/zh-CN/assets/images/2.1.0-agent-node-03d5dea69fdf745ea9e25543761066da.png" width="2462" height="817" class="img_ev3q"></p></li><li><p>新建 COS 类型数据源，选择相应的节点、IP、文件路径即可。</p><p><img loading="lazy" alt="2.1.0-agent-type.png" src="/zh-CN/assets/images/2.1.0-agent-type-191bc679505c8e55464a11d2b4b86748.png" width="2182" height="548" class="img_ev3q"></p><p><img loading="lazy" alt="2.1.0-agent-param.png" src="/zh-CN/assets/images/2.1.0-agent-param-2f2721b5691d985cd00093a5a08b7168.png" width="851" height="698" class="img_ev3q"></p></li></ul><p>该功能支持从 COS 存储直接采集数据，业务不需要把 COS 文件下载到本地再做数据采集。
感谢 @<a href="https://github.com/justinwwhuang" target="_blank" rel="noopener noreferrer">justinwwhuang</a> 的贡献，详情参考 <a href="https://github.com/apache/inlong/issues/11187" target="_blank" rel="noopener noreferrer">INLONG-11187</a></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-支持通过-inlong-sdk-进行脏数据的归档">Sort 支持通过 InLong SDK 进行脏数据的归档<a href="#sort-支持通过-inlong-sdk-进行脏数据的归档" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>新增通过 InLong SDK 上报脏数据至指定 GroupId 和 StreamId 的能力。用户可以选择将脏数据接出，或从 Pulsar 中自主消费。</p><p><img loading="lazy" alt="2.1.0-sort-dirty.png" src="/zh-CN/assets/images/2.1.0-sort-dirty-b167c4568a5d31d7ffe49701acda5d89.png" width="1500" height="1187" class="img_ev3q"></p><p>需要在 Connector 中增加如下配置</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">'dirty.side-output.inlong-sdk.inlong-auth-key' = 'your auth key',</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">'dirty.side-output.inlong-sdk.inlong-auth-id' = 'your auth id',</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">'dirty.side-output.enable' = 'true',</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">'dirty.side-output.inlong-sdk.inlong-group-id' = 'target_inlong_group_id',</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">'dirty.side-output.inlong-sdk.inlong-stream-id' = 'target_inlong_stream_id',</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">'dirty.side-output.labels' = 'groupId=xx&amp;streamId=xx&amp;serverType=tube&amp;dataflowId=xx',</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">'dirty.side-output.inlong-sdk.inlong-manager-addr' = 'xxx',</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">'dirty.side-output.connector' = 'inlong-sdk',</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">'dirty.ignore' = 'true',`</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>感谢 @<a href="https://github.com/vernedeng" target="_blank" rel="noopener noreferrer">vernedeng</a> 和 @<a href="https://github.com/fuweng11" target="_blank" rel="noopener noreferrer">fuweng11</a> 的贡献，
详情参考 <a href="https://github.com/apache/inlong/issues/11481" target="_blank" rel="noopener noreferrer">INLONG-11481</a> 和 <a href="https://github.com/apache/inlong/issues/11508" target="_blank" rel="noopener noreferrer">INLONG-11508</a></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="未来规划">未来规划<a href="#未来规划" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>在 2.1.0 版本中，我们丰富、完善了运维能力。欢迎大家使用，如果有更多场景和需求，或者使用期间遇到的问题， 欢迎大家提 issue和 PR。在后续的版本中，InLong 社区将继续：</p><ul><li><p>支持更多数据源采集能力</p></li><li><p>丰富 Flink 1.15、1.18 Connector</p></li><li><p>丰富 Transform 能力，并且集成到 InLong 的各个模块</p></li><li><p>实时同步支持更多数据源、数据目标</p></li><li><p>优化 SDK 能力和使用体验</p></li><li><p>优化 Dashboard 体验</p></li></ul><p>我们也期待更多对 InLong 感兴趣的开发者可以参与贡献。</p>]]></content>
        <author>
            <name>justinwwhuang</name>
            <uri>https://github.com/justinwwhuang</uri>
        </author>
        <category label="Apache InLong" term="Apache InLong"/>
        <category label="Version" term="Version"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[2.0.0 版本发布]]></title>
        <id>https://inlong.apache.org/zh-CN/blog/2024/10/20/release-2.0.0</id>
        <link href="https://inlong.apache.org/zh-CN/blog/2024/10/20/release-2.0.0"/>
        <updated>2024-10-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Apache InLong（应龙）最近发布了 2.0.0 版本，该版本关闭了 315+ 个 Issues ，包括 6+ 个大特性和 96+ 个优化，主要完成了：支持 Transform SDK 并且集成到 Sort Standalone 的 ES Sink、 OceanBase 数据源管理、Sort 资源自适应配置、SortStandalone HTTP 接出、社区文档重构、全链路支持了离线同步等特性。]]></summary>
        <content type="html"><![CDATA[<p>Apache InLong（应龙）最近发布了 2.0.0 版本，该版本关闭了 315+ 个 Issues ，包括 6+ 个大特性和 96+ 个优化，主要完成了：支持 Transform SDK 并且集成到 Sort Standalone 的 ES Sink、 OceanBase 数据源管理、Sort 资源自适应配置、SortStandalone HTTP 接出、社区文档重构、全链路支持了离线同步等特性。
2.0.0 发布后，Apache InLong 新增了 transform 能力， 完善了Agent Pulsar Source 的支持，丰富了 Sort 的能力和适用场景，同时优化了 InLong Dashboard 的展示，以及 InLong 运营、运维过程中遇到的一些问题和使用体验。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="关于-apache-inlong">关于 Apache InLong<a href="#关于-apache-inlong" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>作为业界首个一站式、全场景海量数据集成框架，Apache InLong（应龙）提供了自动、安全、可靠和高性能的数据传输能力，方便业务快速构建基于流式的数据分析、建模和应用。目前 InLong 正广泛应用于广告、支付、社交、游戏、人工智能等各个行业领域，服务上千个业务，其中高性能场景数据规模超百万亿条/天，高可靠场景数据规模超十万亿条/天。</p><p>InLong 项目定位的核心关键词是“一站式”、“全场景”和“海量数据”。对于“一站式”，我们希望屏蔽技术细节、提供完整数据集成及配套服务，实现开箱即用；对于“全场景”，我们希望提供全方位的解决方案，覆盖大数据领域常见的数据集成场景；对于“海量数据”，我们希望通过架构上的数据链路分层、全组件可扩展、自带多集群管理等优势，在百万亿条/天的基础上，稳定支持更大规模的数据量。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="从-10-到-20">从 1.0 到 2.0<a href="#从-10-到-20" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>在 1.13.0 版本中，InLong 增加了离线同步任务底层框架的搭建，后台支持了 Flink 流批一体能力，2.0.0 版本修复了内置调度器的一些问题，打通了前后端，支持在 Dashboard 页面中配置离线同步任务，全流程支持了离线同步任务的配置和管理，基于此项能力，用户可以统一对实时和离线同步任务进行管理。</p><p>在历史版本中，InLong 的标准和轻量化架构都把能力聚焦在数据采集、上报和数据入库入湖上，对于数据的一些细粒度操作支持较弱，因此，在 1.13.0 版本之后，InLong 社区一项非常重要的工作就是增加对 Transform 支持，通过 Transform 的能力，用户可以在数据集成的任何阶段对数据做更多灵活的处理。</p><p>Transfrom 基于通用的 SQL 语义实现，目前已经完成了 Transfrom 能力框架的搭建，支持了 180+ Transform 自定义函数，并且从设计上保证了 Transform 的扩展性，用户可以灵活自定义新的 Transform 能力。</p><p>除了 Transform 特性之外，InLong 社区的另一项重点是对社区文档进行了重构，一方面补齐了缺失的文档并且更新了过时的内容，另一方面按照用户指引、系统核心介绍、开发指引、系统管理等维度重新组织了文档，对整个系统从用户视角、开发视角和运维视角提供更好的阐释。基于重构后的文档，用户可以更加方便的使用 InLong、更好的理解 InLong 的运行和运营管理机制，也可以快速的进行自定义插件的开发来满足一些定制化需求。</p><p>总的来说，截至 2.0.0 版本发布：</p><ul><li>InLong 完成了对离线同步任务的全链路支持，具备了流批一体的数据处理能力</li><li>InLong 极大的丰富了 T 的能力，也为以后支持 ELT/EtLT Pipeline 等奠定了基础</li><li>文档的优化让 InLong 更加的用户友好，可以更好的吸引用户来了解、使用和共建 InLong</li></ul><p>InLong 目前已经支持了标准和轻量化两种架构、流批一体的数据同步能力、灵活的数据 Transfrom 能力，因此社区决定将 InLong 的版本升级到 2.0.0，Apache InLong 也正式进入 2.0 时代。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="200-版本总览">2.0.0 版本总览<a href="#200-版本总览" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>Apache InLong（应龙）最近发布了 2.0.0 版本，该版本关闭了 315+ 个 Issues ，包括 6+ 个大特性和 96+ 个优化，完成了：</p><ul><li>支持 Transform SDK 并且集成到 Sort Standalone 的 ES Sink</li><li>新增对 OceanBase 数据源管理能力 </li><li>Sort 任务资源自适应配置 </li><li>Sort Standalone HTTP 接出 </li><li>重构、优化了 InLong 社区文档 </li><li>流批一体，全链路支持离线同步能力</li></ul><p>除此上述特性之外，2.0.0 版本还： </p><ul><li>完善了 Agent Pulsar Source 的支持 </li><li>丰富了 Sort 的能力和使用场景 </li><li>修复了 InLong 运营、运维过程中遇到的一些问题 </li><li>优化了 Dashboard 的展示和使用体验</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-模块">Agent 模块<a href="#agent-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>优化 Pulsar Source 实现，修复消费位点不准确问题</li><li>支持数据补录过滤能力</li><li>支持 Agent 状态上报能力</li><li>更新 Redis、Oracle、SQLServer、MQTT 数据源实现</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dashboard-模块">Dashboard 模块<a href="#dashboard-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>数据同步增加离线同步配置页面</li><li>优化数据预览样式结构</li><li>集群节点管理增加心跳显示页面</li><li>数据源信息显示添加集群名称</li><li>源数据字段分隔符支持自定义 ASCII 代码选项</li><li>模块审核页面指标项与其他项合并</li><li>集群管理和模板管理支持删除操作</li><li>修复数据预览错误</li><li>支持 OceanBase 数据源</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-模块">Manager 模块<a href="#manager-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持 OceanBase 数据源管理</li><li>增加 Sort Standalone 的 TubeMQ 配置能力</li><li>支持 Agent 异步安装、支持 Agent 安装日志展示</li><li>支持配置 HTTP 类型 Sink</li><li>支持分页查询排序任务详细信息</li><li>数据预览支持 KV 数据类型、支持转义字符、支持根据 StreamId 过滤 Tube 数据</li><li>支持数据过滤功能</li><li>权限优化：普通用户不是 Owner 时不允许修改 Group 信息</li><li>修复离线同步更新异常</li><li>修复数据预览字段未对齐问题</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sdk-模块">SDK 模块<a href="#sdk-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>Transform 支持使用 GroupBy 语义进行数据分片</li><li>Transform 支持解析 JSON 或 PB 数据中的 Map 节点</li><li>Transform JSON 数据源支持多维数组</li><li>Transform 支持 ELT 功能</li><li>Transform 支持 Transform 注解配置以及解析</li><li>Transform 支持多种类型数据源：JSON、PB、XML、YAML、BSON、AVRO、ORC、PARQUET 等</li><li>Transform 支持算术函数：ceil、floor、sin、cos、cot、tanh、cosh、asin、ata、mod 等</li><li>Transform 支持日期和时间函数：year、 quarter、 month、 week、 form_unixtime、unix_timestamp、 to_timestamp 等</li><li>Transform 支持字符串函数：substring、replace、 reverse 等</li><li>Transform 支持常用编码以及加密函数：MD5、ASCII、SHA</li><li>Transform 支持进制和位运算函数：HEX、Bitwise</li><li>Transform 支持压缩和解压缩函数: GZIP、ZIP 等</li><li>Transform 其他常用函数：大小写转换、IN、NOT IN、EXISTS 等</li><li>DataProxy Java SDK: Shaded Native Library 以减少与其他 sdk 的冲突</li><li>DataProxy Java SDK: 优化元数据变更时的发送抖动问题</li><li>DataProxy CPP SDK: 优化内存管理、优化编译脚本</li><li>DataProxy CPP SDK: 支持多种协议</li><li>DataProxy CPP SDK: 添加消息管理器、优化接收数据的能力</li><li>DataProxy CPP SDK: 支持 DataProxy CPP SDK 的 fork 子进程</li><li>DataProxy Python SDK: 更新构建脚本，并且支持跳过 CPP SDK 构建步骤</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-模块">Sort 模块<a href="#sort-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>根据数据规模调整 Sort 任务需要的资源</li><li>支持 OceanBase 数据源</li><li>Flink 1.18 中支持 Elasticsearch6 和 Elasticsearch7 connector</li><li>SortStandalone Elasticsearch Sink 支持 Transform</li><li>SortStandalone 支持 HTTP Sink，并且支持批量排序</li><li>Connector 支持 OpenTelemetry 日志上报</li><li>优化 Kafka connector 生产者参数</li><li>增加 Flink 1.15 端到端测试用例</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="audit-模块">Audit 模块<a href="#audit-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持审核 SDK 全局内存控制</li><li>优化天维度审计数据统计</li><li>审计 SDK 支持自定义设置本地 IP</li><li>统一审计聚合间隔范围</li><li>解决 Audit SDK 与其他组件 Protobuf 版本冲突</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="200-版本特性介绍">2.0.0 版本特性介绍<a href="#200-版本特性介绍" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="新增-transform-能力">新增 Transform 能力<a href="#新增-transform-能力" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>InLong Transform 助力 InLong 扩展接入分发能力，接入侧适配更丰富的数据协议和上报场景，分发侧适配复杂多样的数据分析场景，
提高数据质量和数据协作，提供连接、聚合、筛选、分组、取值、抽样等和计算引擎解耦的计算能力，简化用户上报数据的前置操作，降低数据使用门槛，
简化用户开始分析数据前的前置操作，聚焦数据的业务价值，实现数据“可见即可用”。</p><p><img loading="lazy" alt="2.0.0-transform-background.png" src="/zh-CN/assets/images/2.0.0-transform-background-dc6607a0a6f2c26255cf99ac3c6dd08b.png" width="1494" height="549" class="img_ev3q"></p><p>Transform 具有非常广泛的应用场景，以下是一些典型的应用场景：</p><ul><li>数据清洗：在数据集成过程中，需要对来自不同源的数据进行清洗，以消除数据中的错误、重复和不一致。Transform 能力可以帮助企业更有效地进行数据清洗，提高数据质量</li><li>数据融合：将来自不同数据源的数据融合在一起，以便进行统一的分析和报告。Transform 能力可以处理不同格式和结构的数据，实现数据的融合和集成</li><li>数据标准化：将数据转换为统一的标准格式，以便进行跨系统和跨平台的数据分析。Transform 能力可以帮助企业实现数据的标准化和规范化</li><li>数据分区和索引：为了提高数据查询和分析的性能，对数据进行分区和建立索引。Transform 能力可以实现分区和索引的字段值动态调整，从而提高数据仓库的性能</li><li>数据聚合和计算：在数据分析过程中，通过对数据进行聚合和计算，提取有价值的业务信息。Transform 能力可以实现复杂的数据聚合和计算，覆盖多维度的数据分析</li><li>数据安全和隐私保护：在数据集成过程中，需要确保数据的安全和隐私。Transform 能力可以实现数据的脱敏、加密和授权管理，保护数据的安全和隐私</li><li>跨团队数据共享：出于数据安全考虑，只共享数据流的筛选子集；出于数据依赖解耦考虑，和合作团队约定数据接口，动态调整多流合并到数据流接口</li></ul><p>Transform 的主要特性如下：</p><ul><li>支持丰富的数据协议</li><li>计算引擎解耦</li><li>支持丰富的转换函数</li><li>支持无损无感变更</li><li>支持自动扩缩容</li></ul><p>目前 Transform 已经在支持了丰富的数据格式以及丰富的自定义函数，用户可以通过 SQL 的方式灵活的对数据进行处理，感谢 @luchunliang, @vernedeng, @emptyOVO, @ying-hua, @Zkplo, @MOONSakura0614, @Ybszzzziz 等同学的贡献，
详情可以参考 <a href="https://github.com/aloyszhang/inlong/blob/master/CHANGES.md#sdk" target="_blank" rel="noopener noreferrer">Transform SDK Issues</a>。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="社区文档重构">社区文档重构<a href="#社区文档重构" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>随着 InLong 社区的不断发展，InLong 能力也在不断增强，社区文档存在缺失或者更新不及时的问题，针对于这个问题， InLong 社区发起了对于社区文档的重构，以便更好地帮助用户了解和使用 InLong。</p><p>主要的内容包括：</p><ul><li>优化文档结构，更好地组织文档内容</li><li>快速开始使用示例完善：<ul><li>离线同步使用示例</li><li>Transform SDK 使用示例</li><li>数据订阅使用示例</li><li>HTTP 消息上报使用示例</li></ul></li><li>SDK 使用文档完善<ul><li>DataProxy：C++、Java、Golang、Python SDK 以及 HTTP 数据上报使用手册</li><li>TubeMQ SDK：C++、Java、Golang SDK 使用手册</li></ul></li><li>开发指引完善<ul><li>代码编译指引</li><li>各组件数据协议文档</li><li>各组件扩展开发文档</li><li>REST API</li></ul></li><li>管理文章完善：用户完善、审批管理、租户管理、节点管理、集群管理、标签管理、模版管理、agent 管理文档</li></ul><p>目前社区文档在使用指引、开发指引、管理指引等方面都有了较大的提升，感谢 @aloyszhang, @fuweng11, @vernedeng, @luchunliang, @gosonzhang, @doleyzi, @baomingyu, @justinwwhuang, @wohainilaodou 等同学对文档重构的贡献，详情请参考<a href="https://inlong.apache.org/docs/next/introduction" target="_blank" rel="noopener noreferrer">官网</a>。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="新增-oceanbase-数据源">新增 OceanBase 数据源<a href="#新增-oceanbase-数据源" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>OceanBase Database 是一个分布式关系型数据库，具有高可用、高扩展性等特点，适用于大规模数据存储和处理场景， InLong 2.0.0 版本增加了对 OceanBase 数据源的支持，可以将数据从数据源导入到 OceanBase 中。
OceanBase 数据节点的管理和 MySQL 类似，新建 OceanBase 节点需要填写节点名称、类型（OceanBase）、用户名、密码、地址等关键信息。</p><p><img loading="lazy" alt="2.0.0-oceanbase-detail.png" src="/zh-CN/assets/images/2.0.0-oceanbase-detail-9dcbff076cae1bab0be268cb72e7b470.png" width="708" height="577" class="img_ev3q"></p><p>将数据写入到 OceanBase，首先需要创建 <code>OceanBase</code> 类型的数据目标，</p><p><img loading="lazy" alt="2.0.0-oceanbase-type.png" src="/zh-CN/assets/images/2.0.0-oceanbase-type-f6e3b3a9d50876c7f79cd54ca867190b.png" width="1256" height="318" class="img_ev3q"></p><p>然后填写相关信息，包括：名称，数据节点信息，数据目标的库、表名称，以及目标表主键信息。</p><p><img loading="lazy" alt="2.0.0-oceanbase-target.png" src="/zh-CN/assets/images/2.0.0-oceanbase-target-78b50473c522ddb7972391cb72edaa71.png" width="1253" height="439" class="img_ev3q"></p><p>感谢 @xxsc0529 对此功能的贡献，具体请参考 <a href="https://github.com/apache/inlong/pull/10700" target="_blank" rel="noopener noreferrer">INLONG-10700</a>、<a href="https://github.com/apache/inlong/pull/10701" target="_blank" rel="noopener noreferrer">INLONG-10701</a>、<a href="https://github.com/apache/inlong/pull/10704" target="_blank" rel="noopener noreferrer">INLONG-10704</a>。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持动态计算-sort-任务的资源">支持动态计算 Sort 任务的资源<a href="#支持动态计算-sort-任务的资源" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>Flink Sort Job 的资源总量（任务并行度）来自于配置文件 <code>flink-sort-plugin.properties</code>，这意味着所有提交的排序作业都会使用相同数量的资源。
当数据规模大时，资源可能不足，当数据规模小时，资源可能浪费。</p><p>因此，根据数据量动态计算资源数量是一个非常需要的功能。 InLong 现在支持根据数据量动态计算任务所需要的资源总量，涉及两个核心数据：</p><ul><li>任务的数据量：数据量依赖于审计系统，取自审计系统统计到的 <code>DataProxy</code> 过去一小时平均数据量</li><li>单核的处理能力：单核的处理能力依赖于配置文件 <code>flink-sort-plugin.properties</code> 中配置的一个核的最大消息数</li></ul><p>有了这两个数据，就可以计算出一个任务所需要的资源总量。 该功能支持开关，可以根据需要选择打开或关闭。</p><p>感谢 @PeterZh6 对此功能的贡献，具体请参考 <a href="https://github.com/apache/inlong/pull/10916" target="_blank" rel="noopener noreferrer">INLONG-10916</a>。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sortstandalone-支持--http-接出">SortStandalone 支持  HTTP 接出<a href="#sortstandalone-支持--http-接出" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>Inlong SortStandalone 负责从 MQ 消费数据，然后分发到不同数据存储的模块，支持 ElasticSearch、CLS 等多种数据存储。</p><p>相比于 SortFlink, SortStandalone 具有更高的性能和更低的延迟，适用于对性能要求较高的场景。</p><p>HTTP 协议是被广泛使用的一种通信协议，SortStandalone 支持 HTTP 接出，可以将数据发送到 HTTP 接口，而不需要关心具体的存储实现，可以更加灵活的适应不同的业务场景。</p><p>HTTP 接出的处理流程如下：</p><p><img loading="lazy" alt="2.0.0-sortstandalone-http.png" src="/zh-CN/assets/images/2.0.0-sortstandalone-http-ac60f52aecb648d113acf8c77190c28c.png" width="1600" height="951" class="img_ev3q"></p><p>HTTP 接出具备以下特点：</p><ul><li>SortSDK 负责从 MQ 消费数据</li><li>支持基于信号量的流量控制能力</li><li>元数据管理依赖 Manager，支持动态更新</li><li>接出协议为 HTTP，解耦具体存储实现</li><li>支持重试策略</li></ul><p>感谢 @yfsn666 和 @fuweng11 对此功能的贡献，具体请参考 <a href="https://github.com/apache/inlong/pull/10831" target="_blank" rel="noopener noreferrer">INLONG-10831</a> 和 <a href="https://github.com/apache/inlong/pull/10884" target="_blank" rel="noopener noreferrer">INLONG-10884</a>。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="离线同步的全链路管理">离线同步的全链路管理<a href="#离线同步的全链路管理" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>2.0.0 版本增加了离线数据同步任务的全链路管理能力，配置离线同步任务的方式和实时同步类似，具体流程如下。
首先创建同步任务的 Group 信息，</p><p><img loading="lazy" alt="2.0.0-offline-sync-group.png" src="/zh-CN/assets/images/2.0.0-offline-sync-group-f247a10d8d9cc1650b2e128ce43377b7.png" width="1495" height="741" class="img_ev3q"></p><p>这里注意“同步类型”选择为“离线”。</p><p>第二步，配置离线任务的调度信息，</p><p><img loading="lazy" alt="2.0.0-offline-schedule-common.png" src="/zh-CN/assets/images/2.0.0-offline-schedule-common-50b39426940a27daaaac2f92b1753ba9.png" width="1494" height="601" class="img_ev3q"></p><p>常规调度配置需要设置以下参数： </p><ul><li>调度单位：支持分钟、小时、天、月、年以及单次，单次表示只执行一次 </li><li>调度周期：表示两次任务调度之间的时间间隔 </li><li>延迟时间：表示任务启动的延迟时间 </li><li>有效时间：包括起始时间和结束时间，调度任务只会在这个时间范围内执行</li></ul><p>除了常规调度方式，还支持 Crontab 的配置方式，</p><p><img loading="lazy" alt="2.0.0-offline-schedule-crontab.png" src="/zh-CN/assets/images/2.0.0-offline-schedule-crontab-6253e29dde6173f342ff94c464701485.png" width="1493" height="419" class="img_ev3q"></p><p>Crontab调度需要设置以下参数： </p><ul><li>有效时间：包括起始时间和结束时间，调度任务只会在这个时间范围内执行 </li><li>crontab 表达式：表示任务的周期，比如 <code>0 */5 * * * ?</code></li></ul><p>第三步，创建 Stream 并且配置数据源和数据目标信息，过程和实时同步一致，不再赘述，详情可以参考 <a href="https://inlong.apache.org/zh-CN/docs/next/quick_start/offline_data_sync/pulsar_mysql_example" target="_blank" rel="noopener noreferrer">离线同步 Pulsar-&gt;MySQL</a> 。</p><p>感谢 @wohainilaodou 的贡献，详情参考 <a href="https://github.com/apache/inlong/issues/10779" target="_blank" rel="noopener noreferrer">INLONG-10779</a>。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="总结与未来规划">总结与未来规划<a href="#总结与未来规划" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>2.0.0 版本是 2.x 第一个版本，技术能力框架基本搭建完成，欢迎大家使用，如果有更多场景和需求，或者使用期间遇到的问题， 欢迎大家提 issue和 PR。在后续的版本中，InLong 社区将继续：</p><ul><li>支持更多数据源采集能力</li><li>丰富 Flink 1.15、1.18 Connector </li><li>持续丰富 Transform 能力</li><li>实时同步支持更多数据源、数据目标</li><li>推进离线集成，支持第三方调度引擎</li><li>优化 SDK 能力和使用体验</li><li>优化 Dashboard 体验</li></ul><p>我们也期待更多对 InLong 感兴趣的开发者可以参与贡献。</p>]]></content>
        <author>
            <name>Aloys Zhang</name>
            <uri>https://github.com/aloyszhang</uri>
        </author>
        <category label="Apache InLong" term="Apache InLong"/>
        <category label="Version" term="Version"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[1.13.0 版本发布]]></title>
        <id>https://inlong.apache.org/zh-CN/blog/2024/07/18/release-1.13.0</id>
        <link href="https://inlong.apache.org/zh-CN/blog/2024/07/18/release-1.13.0"/>
        <updated>2024-07-18T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Apache InLong（应龙）最近发布了 1.13.0 版本，该版本关闭了 275+ 个 Issues ，包含 6+ 个大特性和 100+ 个优化，主要完成了支持 SSH 安装 Agent、字段模板管理能力、支持配置离线同步任务、Agent 采集 PostgreSQL 等特性。1.13.0 发布后，Apache InLong 丰富并优化了 Agent 功能场景， 增强了 Audit 数据度量的准确性，丰富了 Sort 的能力和适用场景，同时优化了 Apache InLong 运营、运维过程中遇到的一些问题和使用体验。]]></summary>
        <content type="html"><![CDATA[<p>Apache InLong（应龙）最近发布了 1.13.0 版本，该版本关闭了&nbsp;275+ 个 Issues ，包含&nbsp;6+ 个大特性和 100+ 个优化，主要完成了支持 SSH 安装 Agent、字段模板管理能力、支持配置离线同步任务、Agent 采集 PostgreSQL 等特性。1.13.0 发布后，Apache InLong 丰富并优化了 Agent 功能场景， 增强了 Audit 数据度量的准确性，丰富了 Sort 的能力和适用场景，同时优化了 Apache InLong 运营、运维过程中遇到的一些问题和使用体验。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="关于-apache-inlong">关于 Apache InLong<a href="#关于-apache-inlong" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>作为业界首个一站式、全场景海量数据集成框架，Apache InLong（应龙）提供了自动、安全、可靠和高性能的数据传输能力，方便业务快速构建基于流式的数据分析、建模和应用。目前 InLong 正广泛应用于广告、支付、社交、游戏、人工智能等各个行业领域，服务上千个业务，其中高性能场景数据规模超百万亿条/天，高可靠场景数据规模超十万亿条/天。</p><p>InLong 项目定位的核心关键词是“一站式”、“全场景”和“海量数据”。对于“一站式”，我们希望屏蔽技术细节、提供完整数据集成及配套服务，实现开箱即用；对于“全场景”，我们希望提供全方位的解决方案，覆盖大数据领域常见的数据集成场景；对于“海量数据”，我们希望通过架构上的数据链路分层、全组件可扩展、自带多集群管理等优势，在百万亿条/天的基础上，稳定支持更大规模的数据量。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="1130-版本总览">1.13.0 版本总览<a href="#1130-版本总览" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>Apache InLong（应龙）最近发布了 1.13.0 版本，该版本关闭了&nbsp;275+ 个 Issues ，包含&nbsp;6+ 个大特性和 100+ 个优化，主要完成了支持 SSH 安装 Agent、字段模板管理能力、支持配置离线同步任务、Agent 采集 PostgreSQL 等特性。1.13.0 发布后，Apache InLong 丰富并优化了 Agent 功能场景，增强了 Audit 数据度量的准确性，丰富了 Sort 的能力和适用场景，同时优化了 Apache InLong 运营、运维过程中遇到的一些问题和使用体验。Apache InLong 1.13.0 版本中，还完成了大量其它特性，主要包括：</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-模块">Agent 模块<a href="#agent-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持数据版本号，用于区分正常数据与补录数据</li><li>位点存储支持插件化，目前支持 Rocksdb 与 Zookeeper</li><li>支持配置版本号比对，防止配置反复</li><li>支持分钟级文件采集</li><li>增加 PostgreSQL 数据源采集</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-模块">Manager 模块<a href="#manager-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持通过 SSH 的方式安装 Agent</li><li>审计 ID 查询从直接与数据库交互切换至 Audit SDK</li><li>离线同步支持 Pulsar -&gt; MySQL </li><li>支持离线同步调度信息管理</li><li>文件采集支持多 IP 采集</li><li>支持获取 Agent 配置信息</li><li>支持修改 Stream 字段信息后自动同步至 Sink</li><li>支持字段模板管理</li><li>数据预览支持 KV 格式</li><li>数据预览支持根据字段过滤条件查询</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dashboard-模块">Dashboard 模块<a href="#dashboard-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>新增源数据字段模板页面</li><li>新增监控审计页面</li><li>支持通过基于 SSH 密钥的身份验证安装 Agent</li><li>审计支持显示总计和差异的审计数据</li><li>文件类型数据流支持分钟级周期</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="audit-模块">Audit 模块<a href="#audit-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>Audit SDK 统一分配与管理审计项</li><li>Audit SDK 支持自动管理 Audit Proxy 地址</li><li>Audit Store 支持通用 JDBC 协议</li><li>Audit Store 优化进程重启可能导致丢数据的问题</li><li>Audit Service 优化线程池管理</li><li>Audit Service 兼容 Audit Tag 为空的历史审计数据</li><li>Audit Service 优化 OpenAPI 审计传输时延的计算</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-模块">Sort 模块<a href="#sort-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>新增 JDBC connector on flink 1.15</li><li>新增 Pulsar connector on flink 1.18</li><li>Redis connector支持 上报审计信息</li><li>Kafka connector 支持上报审计信息</li><li>MongoDB connector 支持上报审计信息</li><li>PostgreSQL connector 支持上报审计信息</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sdk-模块">SDK 模块<a href="#sdk-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>新增 DataProxy Python SDK</li><li>DataProxy Python SDK 增强 Transform SDK SQL函数支持，新增8种算术函数(power, abs, sqrt, ln, log10, log2, log, exp)</li><li>DataProxy Go SDK 连接池支持动态均衡及故障节点恢复探测</li><li>DataProxy Go SDK 修复 gnet 初始化顺序的问题，避免升级到新版本gnet会阻塞</li><li>DataProxy Go SDK 潜在的阻塞问题，避免更新连接时阻塞</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="1130-版本特性介绍">1.13.0 版本特性介绍<a href="#1130-版本特性介绍" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-支持-ssh-安装-agent">Manager 支持 SSH 安装 Agent<a href="#manager-支持-ssh-安装-agent" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>通过此特性，运维人员可以通过 Dashboard 进行 Agent 的安装操作，目前支持通过 SSH 和手动安装的方式。用户可以在集群管理页面新建 Agent 集群。</p><p><img loading="lazy" alt="1.13.0-agent-cluster.png" src="/zh-CN/assets/images/1.13.0-agent-cluster-937d9c5bc3f0b31b10db05156808315e.png" width="1014" height="686" class="img_ev3q"></p><p>之后，进入节点，选择新建节点并配置好 SSH 用户名和密码后实现 SSH 安装 Agent 能力。
感谢 @haifxu、@fuweng11 两位同学在 Dashboard 及 Manager 部分对此功能的贡献。具体可参考：INLONG-10409。</p><p><img loading="lazy" alt="1.13.0-agent-install.png" src="/zh-CN/assets/images/1.13.0-agent-install-e595054066325ff6439a8f895bd02f58.png" width="1020" height="1322" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-支持字段模板管理能力">Manager 支持字段模板管理能力<a href="#manager-支持字段模板管理能力" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>通过此特性，用户可以事先配置好字段模板，在新建 Stream 时，可以选择已配置好的字段模板，从而达到多个 Stream 复用配置的目的。
感谢 @kamianlaida、@fuweng11 两位同学在 Dashboard 及 Manager 部分对此功能的贡献。具体可参考：INLONG-10330。</p><p><img loading="lazy" alt="1.13.0-create-template.png" src="/zh-CN/assets/images/1.13.0-create-template-59a3546b3b47c1295137456b6ce9f67b.png" width="1978" height="978" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持配置离线同步任务底层框架搭建">支持配置离线同步任务底层框架搭建<a href="#支持配置离线同步任务底层框架搭建" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 1.13.0 版本中，InLong 支持了离线同步任务的配置，与实时同步相比，离线数据同步更注重同步吞吐量和效率。
该实现统一基于 Flink 计算引擎。实时同步任务以 Flink 流任务的方式运行，而离线同步则以 Flink 批处理任务的方式进行。这种方法可以尽可能地确保实时和离线同步任务代码的一致性，从而降低维护成本。
InLong 的离线同步功能将与调度系统相结合，将数据源信息的完整或增量数据同步到数据目标，离线同步任务由 InLong Manager 创建（包括调度信息），具体的数据同步逻辑通过 InLong Sort 模块实现。</p><p><img loading="lazy" alt="1.13.0-offline-architecture.png" src="/zh-CN/assets/images/1.13.0-offline-architecture-eef859714bb87205a461252ee499c44a.png" width="778" height="676" class="img_ev3q"></p><p>关键能力:</p><ul><li>作业类型：支持单次或者周期的离线数据同步</li><li>调度：调度功能插件化，内置简单的周期性调度功能，可以自定义第三方调度系统来支持更复杂的能力，比如任务依赖等</li><li>计算引擎：Flink</li><li>离线作业操作和维护：作业启动、停止和运行状态监控</li><li>特殊处理：脏数据处理能力</li></ul><p>下图为核心流程：</p><p><img loading="lazy" alt="1.13.0-dataflow-architecture.png" src="/zh-CN/assets/images/1.13.0-dataflow-architecture-6750793161a566bf2fca9f938acea1a9.png" width="971" height="1360" class="img_ev3q"></p><p>感谢 @aloyszhang 对此功能的贡献，具体请参考 INLONG-10054, INLONG-10053, INLONG-10055, INLONG-10069。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="优化-sort-standalone-配置流程">优化 Sort Standalone 配置流程<a href="#优化-sort-standalone-配置流程" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 1.13.0 版本中，修改了 Sort Standalone 配置下发流程，在之前的版本中，sort standalone 的配置下发存在以下问题:</p><ul><li>配置变更具有不可靠性。配置变化会实时更新到 manager 的缓存中，一旦配置变更，Sort Standalone 就会感知到，并根据新的配置写入数据，并没有进行对配置的校验。</li><li>配置构建流程重复并且繁琐。从数据库中拉取 Sort 配置时是全量拉取并且在拉取完毕后进行实时构建。
在新的版本中，修改数据目标后，Sort 配置将不会实时生效，而是需要在执行工作流后将 Sort 配置构建写入 sort_config 表中。下图为流程对比:</li></ul><p><img loading="lazy" alt="1.13.0-manager-standalone.png" src="/zh-CN/assets/images/1.13.0-manager-standalone-9462c43bdaf5cb43dabcc5f1c2a860a8.png" width="990" height="731" class="img_ev3q"></p><p>感谢 @fuweng11, @vernedeng 对此功能的贡献，具体请参考 INLONG-9867, INLONG-10017。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-支持-postgresql-采集">Agent 支持 PostgreSQL 采集<a href="#agent-支持-postgresql-采集" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 1.13.0 版本中，Agent 支持了从 PostgreSQL 采集数据，在数据源创建时可以直接选择 PostgreSQL，填写相关数据源信息即可开始使用，参数包括：</p><ul><li>数据源名称：便于快速区分不同的数据源</li><li>集群名称：选择该数据源所属的集群</li><li>数据源 IP：选择该数据源所属的机器</li><li>服务器主机：PostgreSQL 服务器主机</li><li>端口：PostgreSQL 端口</li></ul><p>感谢 @haifxu 对此功能的贡献，具体请参考 INLONG-10318。</p><p><img loading="lazy" alt="1.13.0-agent-postgreSQL.png" src="/zh-CN/assets/images/1.13.0-agent-postgreSQL-b739dad2e8807c4e1aeac9be5f9039a9.png" width="1530" height="1798" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-connectors-上报审计信息支持-exactly-once">Sort Connectors 上报审计信息支持 exactly once<a href="#sort-connectors-上报审计信息支持-exactly-once" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>Sort Connectors 上报审计信息支持 exactly once 语义, 在算子遇见异常，snapshot 失败时，各个 Connector 保证上报审计信息 exactly once。
如下图所示，当数据传输时，会把当前数据写入当前算子 AuditBuffer 以及对应的 checkpointId。当 checkpoint 完成时（在 notifyCompleteCheckpoint 方法中）将写入 buffer 的数据进行上报。</p><p><img loading="lazy" alt="1.13.0-sort-exactly.png" src="/zh-CN/assets/images/1.13.0-sort-exactly-36c81aac716070dd4f670bb47313edb8.png" width="1302" height="563" class="img_ev3q"></p><p>在 snapShot 执行时，会将写入 buffer 的 checkpointId 变更为 snapShot 中的 checkpointId，并在 checkpoint 执行完成时，也就是 notifyCompleteCheckpoint 方法中将审计信息上传至 Audit Server 中。</p><p><img loading="lazy" alt="1.13.0-sort-audit.png" src="/zh-CN/assets/images/1.13.0-sort-audit-c42f5f6914ef55f013bad4648473c966.png" width="1264" height="772" class="img_ev3q"></p><p>感谢 @XiaoYou201 对此功能的贡献，具体请参考 INLONG-10311, INLONG-10312, INLONG-10317, INLONG-10355, INLONG-10357, INLONG-10358, INLONG-10401。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="未来规划">未来规划<a href="#未来规划" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>在 1.13.0 版本中，社区重构了 Manager 下发 Agent、Sort 任务流程，丰富了 Flink 1.15 Connector、Inlong Agent 采集 PostgreSQL 等功能。在后续的版本中，InLong 将继续丰富 Flink 1.15、1.18 Connector 、丰富 Transform 能力、支持离线集成、统一 DataProxy 数据协议、Dashboard 体验优化等，期待更多开发者参与贡献。</p>]]></content>
        <author>
            <name>Wenkai Fu</name>
            <uri>https://github.com/fuweng11</uri>
        </author>
        <category label="Apache InLong" term="Apache InLong"/>
        <category label="Version" term="Version"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[1.12.0 版本发布]]></title>
        <id>https://inlong.apache.org/zh-CN/blog/2024/04/21/release-1.12.0</id>
        <link href="https://inlong.apache.org/zh-CN/blog/2024/04/21/release-1.12.0"/>
        <updated>2024-04-21T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Apache InLong（应龙）最近发布了 1.12.0 版本，该版本关闭了 140+ 个 Issues ，包含 7+ 个大特性和 90+ 个优化，主要完成了 Manager 对 Agent 安装包的管理和自升级流程的管理、Agent 支持自升级流程、Agent 对 Kafka/Pulsar/MongoDB 采集的支持、Audit 方案优化及能力增强、Sort 新增支持 Redis Connector 等特性。1.12.0 发布后，Apache InLong 丰富并优化了 Agent 功能场景， 增强了 Audit 数据度量的准确性，丰富了 Sort 的能力和适用场景，同时优化了 Apache InLong 运营、运维过程中遇到的一些问题和使用体验。]]></summary>
        <content type="html"><![CDATA[<p>Apache InLong（应龙）最近发布了 1.12.0 版本，该版本关闭了&nbsp;140+ 个 Issues ，包含&nbsp;7+ 个大特性和 90+ 个优化，主要完成了 Manager 对 Agent 安装包的管理和自升级流程的管理、Agent 支持自升级流程、Agent 对 Kafka/Pulsar/MongoDB 采集的支持、Audit 方案优化及能力增强、Sort 新增支持 Redis Connector 等特性。1.12.0 发布后，Apache InLong 丰富并优化了 Agent 功能场景， 增强了 Audit 数据度量的准确性，丰富了 Sort 的能力和适用场景，同时优化了 Apache InLong 运营、运维过程中遇到的一些问题和使用体验。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="关于-apache-inlong">关于 Apache InLong<a href="#关于-apache-inlong" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>作为业界首个一站式、全场景海量数据集成框架，Apache InLong（应龙）提供了自动、安全、可靠和高性能的数据传输能力，方便业务快速构建基于流式的数据分析、建模和应用。目前 InLong 正广泛应用于广告、支付、社交、游戏、人工智能等各个行业领域，服务上千个业务，其中高性能场景数据规模超百万亿条/天，高可靠场景数据规模超十万亿条/天。</p><p>InLong 项目定位的核心关键词是“一站式”、“全场景”和“海量数据”。对于“一站式”，我们希望屏蔽技术细节、提供完整数据集成及配套服务，实现开箱即用；对于“全场景”，我们希望提供全方位的解决方案，覆盖大数据领域常见的数据集成场景；对于“海量数据”，我们希望通过架构上的数据链路分层、全组件可扩展、自带多集群管理等优势，在百万亿条/天的基础上，稳定支持更大规模的数据量。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="1120-版本总览">1.12.0 版本总览<a href="#1120-版本总览" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>Apache InLong（应龙）最近发布了 1.12.0 版本，该版本关闭了&nbsp;140+ 个 Issues ，包含&nbsp;7+ 个大特性和 90+ 个优化，主要完成了 Manager 对 Agent 安装包的管理和自升级流程的管理、Agent 支持自升级流程、Agent 对 Kafka/Pulsar/MongoDB 采集的支持、Audit 方案优化及能力增强、Sort 新增支持 Redis Connector 等特性。1.12.0 发布后，Apache InLong 丰富并优化了 Agent 功能场景，增强了 Audit 数据度量的准确性，丰富了 Sort 的能力和适用场景，同时优化了 Apache InLong 运营、运维过程中遇到的一些问题和使用体验。Apache InLong 1.12.0 版本中，还完成了大量其它特性，主要包括：</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-模块">Agent 模块<a href="#agent-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持 Agent 自升级版本</li><li>优化初始化逻辑降低 IO 使用率</li><li>优化消息确认逻辑，减少信号量竞争</li><li>增加异常和重发审计数据</li><li>优化了补数据流程，避免因补文件过多导致丢数据</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-模块">Manager 模块<a href="#manager-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持 Agent、Installer 安装包管理以及自升级流程管理</li><li>支持在数据预览时根据 CSV 等数据类型解析具体字段信息</li><li>数据预览支持多集群条件下查询数据</li><li>数据预览支持获取消息头等额外信息</li><li>支持配置文件采集补录任务</li><li>审计数据查询从直接与数据库交互切换至 Audit OpenAPI</li><li>Pulsar Sink 支持配置 Pulsar SDK 消费时所需压缩格式</li><li>提供批量保存 InLongGroup、InLongStream 等信息的 OpenAPI</li><li>支持 Kafka Datanode 管理</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dashboard-模块">Dashboard 模块<a href="#dashboard-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>审计数据查询优化</li><li>审计数据展示优化</li><li>Sink 字段映射支持下划线“_”</li><li>资源详情展示支持分页</li><li>支持 MongoDB 数据源配置</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="audit-模块">Audit 模块<a href="#audit-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持用户自定义方式获取 Audit proxy 信息</li><li>Audit SDK 支持上报版本号</li><li>Audit SDK 支持单例、非单例两种使用方式</li><li>Audit SDK 支持 Flink Checkpoint 特性下的数据上报方式</li><li>Audit Service 支持 HA 能力</li><li>Audit Service 支持本地缓存及 OpenApi</li><li>Audit Service 支持多数据源集群</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-模块">Sort 模块<a href="#sort-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>StarRocks Connector 在初始化时支持使用 state key</li><li>支持解析含有分割服的 KV、CSV 数据</li><li>使用 ZLIB 作为 Pulsar Sink 的默认压缩类型</li><li>Pulsar Connector 支持认证配置</li><li>Pulsar Sink 支持认证配置</li><li>Redis Source 支持 String、Hash、ZSet 数据类型的读取</li><li>Redis Sink 支持 Bitmap、Hash、String 数据类型</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="1120-版本特性介绍">1.12.0 版本特性介绍<a href="#1120-版本特性介绍" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-支持对-agent-安装管理">Manager 支持对 Agent 安装管理<a href="#manager-支持对-agent-安装管理" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>通过此特性，运维人员可以通过 Dashboard 管理 Agent 的发布包，包括 Agent 安装、升级、心跳管理等。用户在系统运维 -&gt;&gt; 安装包 -&gt;&gt; Agent 页面创建/管理安装包。感谢 @haifxu、@fuweng11 两位同学在 Dashboard 及 Manager 部分对此功能的贡献。具体可参考：INLONG-9932。
<img loading="lazy" alt="1.12.0-agent-package.png" src="/zh-CN/assets/images/1.12.0-agent-package-62f7ba31829a690c0552ef208352a4ed.png" width="1500" height="625" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-支持自升级">Agent 支持自升级<a href="#agent-支持自升级" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>Agent 可以通过提前部署的 Installer 完成自升级操作，Installer 会通过 IP 从 InLong manager 获取升级的配置信息，根据配置判断是否升级主要流程：</p><ul><li>新增流程：下载安装包 -&gt; 解压安装包 -&gt; 启动进程</li><li>删除流程：停止进程 -&gt; 删除安装文件</li><li>更新流程：下载安装包 -&gt; 停止进程 -&gt; 删除安装文件 -&gt; 解压安装包 -&gt; 启动进程
感谢 @justinwwhuang  对此功能的贡献，具体可参考 INLONG-9801 。
<img loading="lazy" alt="1.12.0-agent-upgrade.png" src="/zh-CN/assets/images/1.12.0-agent-upgrade-9f282143b8a7c7b56778bba76bf713f2.png" width="1500" height="834" class="img_ev3q"></li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-支持-kafka-采集">Agent 支持 Kafka 采集<a href="#agent-支持-kafka-采集" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 1.12.0 版本中，Agent 支持了从 Kafka 采集数据，在数据源创建时可以直接选择 Kafka，填写相关数据源信息即可开始使用，参数包括：</p><ul><li>数据源名称：便于快速区分不同的数据源</li><li>集群名称：选择该数据源所属的集群</li><li>数据源 IP：选择该数据源所属的机器</li><li>Bootstrap Servers：Kafka 集群地址</li><li>Topic：改数据源要订阅的 Kafka Topic</li><li>自动偏移重置：设置偏移策略</li><li>分区位点：可精确指定具体分区位点
感谢 @haifxu 对此功能的贡献，具体请参考 INLONG-9741 。
<img loading="lazy" alt="1.12.0-agent-kafka.png" src="/zh-CN/assets/images/1.12.0-agent-kafka-5e3a67e40c9b708026d248aa638faa0b.png" width="1500" height="1192" class="img_ev3q"></li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-支持-pulsar-采集">Agent 支持 Pulsar 采集<a href="#agent-支持-pulsar-采集" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 1.12.0 版本中，Agent 支持了从 Pulsar 采集数据，在数据源创建时可以直接选择 Pulsar，填写相关数据源信息即可开始使用，参数包括：</p><ul><li>数据源名称：便于快速区分不同的数据源</li><li>集群名称：选择该数据源所属的集群</li><li>数据源 IP：选择该数据源所属的机器</li><li>Pulsar 租户：Pulsar 租户</li><li>命名空间：Pulsar 命名空间</li><li>Pulsar topic：数据源要订阅的 topic</li><li>Admin url：Pulsar admin url</li><li>Service url：Pulsar service url
感谢 @justinwwhuang 同学对此功能的贡献，具体可参考 INLONG-9804
<img loading="lazy" alt="1.12.0-agent-pulsar.png" src="/zh-CN/assets/images/1.12.0-agent-pulsar-5d780e7de158c9123673b36f5fba5d47.png" width="1500" height="1870" class="img_ev3q"></li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-支持-mongodb-采集">Agent 支持 MongoDB 采集<a href="#agent-支持-mongodb-采集" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 1.12.0 版本中，Agent 支持了从 MongoDB 采集数据，在数据源创建时可以直接选择 MongoDB，填写相关数据源信息即可开始使用，参数包括：</p><ul><li>数据源名称：便于快速区分不同的数据源</li><li>集群名称：选择该数据源所属的集群</li><li>数据源 IP：选择该数据源所属的机器</li><li>服务器主机：MongoDB 地址</li><li>用户名：MongoDB 用户名</li><li>密码：MongoDB 密码</li><li>数据库名：MongoDB 数据库名</li><li>集合名称：MongoDB 集合名称</li><li>读取模式：可选“全量 + 增量” 或 “增量”
感谢 @justinwwhuang 同学对此功能的贡献，具体可参考 INLONG-10006。
<img loading="lazy" alt="1.12.0-agent-mongodb.png" src="/zh-CN/assets/images/1.12.0-agent-mongodb-69f580e2fc4cf28b9e5354a3f91b7d31.png" width="1500" height="1415" class="img_ev3q"></li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="audit-支持多场景对账">Audit 支持多场景对账<a href="#audit-支持多场景对账" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 1.12.0 版本中，InLong 丰富了 Audit 审计对账的场景，包括支持 Agent 数据补录场景、Sort on Flink Checkpoint 场景等，特别感谢 @doleyzi 同学对此功能的贡献，具体可参考 INLONG-9904、INLONG-9926、INLONG-9928、INLONG-9957 等。</p><ul><li>新增 OpenAPI 能力
在 1.12.0 版本，Audit 新增了 OpenAPI 的能力，各个 OpenAPI 可以通过 HA 进行选主，Leader 节点负责对审计数据源进行实时、回溯聚合，并且将聚合结果保存在 DB 中，Slave 节点负责将 DB 的数据 cache 到内存，对外提供服务( Leader 节点同样也提供该服务)
<img loading="lazy" alt="1.12.0-audit-process.png" src="/zh-CN/assets/images/1.12.0-audit-process-4578adddeb3ce63482dc4ced0e3a7a59.png" width="1500" height="1008" class="img_ev3q"></li><li>新增 Agent 数据补录的能力
在 1.12.0 版本，审计支持了 Agent 数据补录的场景，通过新增 audit-version，区分每次补录的审计对账
<img loading="lazy" alt="1.12.0-audit-recovery.png" src="/zh-CN/assets/images/1.12.0-audit-recovery-a509e8a719ad1c11e31c030a21b894e4.png" width="1500" height="552" class="img_ev3q"></li><li>支持 Sort Flink Checkpoint 能力
在 1.12.0 版本，审计支持了 Sort Flink 的 checkpoint 的场景，在 Flink 作业重启或者 failover 时，能够保证审计数据不丢不重，从而保证全流程的审计对账
<img loading="lazy" alt="1.12.0-audit-checkpoint.png" src="/zh-CN/assets/images/1.12.0-audit-checkpoint-ed769620899f9bce47d8d3a04ebf47fd.png" width="1500" height="760" class="img_ev3q"></li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-新增-redis-connector">Sort 新增 Redis Connector<a href="#sort-新增-redis-connector" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 1.12.0 版本，增加了基于 Flink 1.15 支持的 Redis connector 实现，支持对 Redis 集群和单机的 String、Hash、ZSet、Bitmap 四种常用数据类型读取和写入，在 Redis connector 内部实现了 Schema 转换，可以将用户指定的 Schema 转换为不同的 Redis Data Type。具体 Schema 转换逻辑如下图所示，在下图的 Bitmap 转换逻辑中，field1 作为 Bitmap 的 key， filed2、field4 作为 Bitmap 中的位置(index), filed3、field5 为设置的值(0 或 1)。具体可参考 Redis 原生命令 SETBIT key index value。感谢 @XiaoYou201 同学对此功能的贡献，具体可参考 INLONG-9835、INLONG-8948 。
<img loading="lazy" alt="1.12.0-redis-connector.png" src="/zh-CN/assets/images/1.12.0-redis-connector-b7077838e78c2cd0d337872d2a8254fb.png" width="1500" height="1119" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="未来规划">未来规划<a href="#未来规划" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>在 1.12.0 版本中，社区重构了 InLong Agent，InLong Audit，丰富了 Flink 1.15 Connector 等功能。在后续的版本中，InLong 将继续丰富 Flink 1.15 Connector 、丰富 Transform 能力、支持离线集成、统一 DataProxy 数据协议、Dashboard 体验优化等，期待更多开发者参与贡献。</p>]]></content>
        <author>
            <name>Mingyu Bao</name>
            <uri>https://github.com/baomingyu</uri>
        </author>
        <category label="Apache InLong" term="Apache InLong"/>
        <category label="Version" term="Version"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[1.10.0 版本发布]]></title>
        <id>https://inlong.apache.org/zh-CN/blog/2023/12/13/release-1.10.0</id>
        <link href="https://inlong.apache.org/zh-CN/blog/2023/12/13/release-1.10.0"/>
        <updated>2023-12-13T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Apache InLong（应龙）最近发布了 1.10.0 版本，该版本关闭了约 200+ 个 issue ，包含 6+ 个大特性和 30+ 个优化，主要完成了 Manager 支持查看操作日志、支持 Group 在集群间迁移、Agent 支持周期采集和任务补录、Sort 实时同步支持 Transform、支持 MySQL 到 Iceberg 整库同步、支持自动建表等特性。1.10.0 发布后，Apache InLong 丰富并优化了 Agent 功能场景， 新增整库同步自动建表的能力，支持查看操作日志，解决在开发和运营过程中的快速排查问题的需求，同时优化 Apache InLong 运营运维的使用体验。]]></summary>
        <content type="html"><![CDATA[<p>Apache InLong（应龙）最近发布了 1.10.0 版本，该版本关闭了约 200+ 个 issue ，包含 6+ 个大特性和 30+ 个优化，主要完成了 Manager 支持查看操作日志、支持 Group 在集群间迁移、Agent 支持周期采集和任务补录、Sort 实时同步支持 Transform、支持 MySQL 到 Iceberg 整库同步、支持自动建表等特性。1.10.0 发布后，Apache InLong 丰富并优化了 Agent 功能场景， 新增整库同步自动建表的能力，支持查看操作日志，解决在开发和运营过程中的快速排查问题的需求，同时优化 Apache InLong 运营运维的使用体验。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="关于-apache-inlong">关于 Apache InLong<a href="#关于-apache-inlong" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>作为业界首个一站式、全场景海量数据集成框架，Apache InLong（应龙）提供了自动、安全、可靠和高性能的数据传输能力，方便业务快速构建基于流式的数据分析、建模和应用。目前 InLong 正广泛应用于广告、支付、社交、游戏、人工智能等各个行业领域，服务上千个业务，其中高性能场景数据规模超百万亿条/天，高可靠场景数据规模超十万亿条/天。</p><p>InLong 项目定位的核心关键词是“一站式”、“全场景”和“海量数据”。对于“一站式”，我们希望屏蔽技术细节、提供完整数据集成及配套服务，实现开箱即用；对于“全场景”，我们希望提供全方位的解决方案，覆盖大数据领域常见的数据集成场景；对于“海量数据”，我们希望通过架构上的数据链路分层、全组件可扩展、自带多集群管理等优势，在百万亿条/天的基础上，稳定支持更大规模的数据量。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="1100-版本总览">1.10.0 版本总览<a href="#1100-版本总览" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>Apache InLong（应龙）最近发布了 1.10.0 版本，该版本关闭了约 200+ 个 issue ，包含 6+ 个大特性和 30+ 个优化，主要完成了 Manager 支持查看操作日志、支持 Group 在集群间迁移、Agent 支持周期采集和任务补录、Sort 实时同步支持 Transform、支持 MySQL 到 Iceberg 整库同步、支持自动建表等特性。1.10.0 发布后，Apache InLong 丰富并优化了 Agent 功能场景， 新增整库同步自动建表的能力，支持查看操作日志，解决在开发和运营过程中的快速排查问题的需求，同时优化 Apache InLong 运营运维的使用体验。Apache InLong 1.10.0 版本中，还完成了大量其它特性，主要包括：</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-模块">Agent 模块<a href="#agent-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持周期采集、任务补录</li><li>全局内存控制，避免业务数据较大导致 OOM</li><li>实现 Agent 与 Manager 任务最终一致</li><li>丰富 Agent 审计维度</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-模块">Sort 模块<a href="#sort-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持 MySQL 到 Iceberg 整库同步</li><li>支持更丰富的 Flink 1.15 Connector： MongoDB、Iceberg、SQLServer、HBase</li><li>支持任务状态管理，能够查看实时同步任务实时状态</li><li>实时任务支持自动建表</li><li>支持配置 Transform </li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-模块">Manager 模块<a href="#manager-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持 Sort Standalone 管理</li><li>传输协议与数据协议类型拆分</li><li>支持 Group 集群切换</li><li>支持查询审计数据大小</li><li>支持查看操作日志</li><li>Apache Iceberg 支持自动拉取 Schema 信息</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dashboard-模块">Dashboard 模块<a href="#dashboard-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持同时展示资源创建者以及最近修改者</li><li>支持查看操作日志</li><li>审批目录显示 Group 对应的消费组 </li><li>支持批量解析源字段</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="audit-模块">Audit 模块<a href="#audit-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持服务启动时自动创建需要的 Kafka Topic</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sdk-模块">SDK 模块<a href="#sdk-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>DataProxy Java SDK 解决依赖版本冲突问题 </li><li>DataProxy Go SDK 更新版本依赖 </li><li>DataProxy Go SDK 使用 UUID 替换雪花算法来生成数据 ID </li><li>DataProxy C++ SDK 支持动态负载均衡 </li><li>DataProxy C++ SDK 支持多维度资源隔离 </li><li>DataProxy C++ SDK 优化多地部署下就近接入的能力 </li><li>DataProxy C++ SDK 支持本地容灾 </li><li>DataProxy C++ SDK 支持动态更新 DataProxy 节点信息</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="其他">其他<a href="#其他" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>强化请求伪造攻击保护 </li><li>更新 Snappy 版本 </li><li>增加 Master 分支保护策略</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="1100-版本特性介绍">1.10.0 版本特性介绍<a href="#1100-版本特性介绍" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-支持周期采集">Agent 支持周期采集<a href="#agent-支持周期采集" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>InLong 1.10.0 版本新增周期文件采集任务的能力，周期策略包括天、小时、实时，用户可以在新建文件数据源时指定该策略。同时，用户也可以配置时间偏移量来延迟或提前采集。感谢 @Justinhuang，@Bluewang，@fuwen11 的贡献，详情可见 INLONG-9094， INLONG-9344， INLONG-9356。
<img loading="lazy" alt="1.10.0-periodic-collection.png" src="/zh-CN/assets/images/1.10.0-periodic-collection-cea99a6d3d45cd31932529f3dcd71de0.png" width="1500" height="1043" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持按-ip-维度查看-agent-审计">支持按 IP 维度查看 Agent 审计<a href="#支持按-ip-维度查看-agent-审计" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>为了更好地监控 InLong Agent 的状态，方便在现网运行中快速发现问题，在 1.10.0 版本中，用户可以在系统运维-&gt;审计模块里根据 IP 维度查看 Agent 审计不同指标。感谢 @fuwen11，@Bluewang 和 @Justinhuang 的贡献，详情可见 INLONG-9443，INLONG-9446 和 INLONG-9458
<img loading="lazy" alt="1.10.0-agent-audit.png" src="/zh-CN/assets/images/1.10.0-agent-audit-b964a429be29ae03d66ab6b1bd4b0673.png" width="1500" height="370" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-新增-group-操作日志">Manager 新增 Group 操作日志<a href="#manager-新增-group-操作日志" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 1.10.0 版本中，InLong 支持查看操作日志， 包括 Group/Stream 的创建和变更，Sink/Source 的新增和下线等操作。操作日志可以快速帮着用户追踪历史行为，用户可以快速查看数据流关键操作，便于现网维护 。用户可以在数据接入-&gt;Group详情-&gt;操作日志里查看 Group 下所有的操作日志：
<img loading="lazy" alt="1.10.0-group-operation-log.png" src="/zh-CN/assets/images/1.10.0-group-operation-log-56d720b4e1bf52d7ad06ada0d36a73af.png" width="1500" height="659" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="新增-group-集群切换的能力">新增 Group 集群切换的能力<a href="#新增-group-集群切换的能力" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>为了支持资源整合以及成本划分的能力，InLong 在 1.10.0 版本引入了 Group 集群切换的特性。直接进行切换必然导致模块间元数据不同步和数据丢失等问题。为了实现业务无感的集群切换能力，Group 集群切被分为三个状态和两个步骤。感谢 @Vernedeng 的贡献，详情可见 INLONG-9314。
<img loading="lazy" alt="1.10.0-group-switching-1.png" src="/zh-CN/assets/images/1.10.0-group-switching-1-79c6d3f94cee8920d7c6332a3ff1e5ed.png" width="1500" height="673" class="img_ev3q">
切换集群前，数据在 Cluster 1 上。
<img loading="lazy" alt="1.10.0-group-switching-2.png" src="/zh-CN/assets/images/1.10.0-group-switching-2-e880f8a1d3f6a78fd047758c4e628a10.png" width="1500" height="673" class="img_ev3q">
开始切换集群后，复制原路由配置，新数据写入 Cluster 2，同时 Cluster 1 上的未发送完的数据继续发送。
<img loading="lazy" alt="1.10.0-group-switching-3.png" src="/zh-CN/assets/images/1.10.0-group-switching-3-252b68c477b2892f5075cd88e7077b59.png" width="1500" height="673" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="c-sdk-支持多维度隔离">C++ SDK 支持多维度隔离<a href="#c-sdk-支持多维度隔离" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在老版本 C++ SDK 中，所有 Group 通过竞争的方式来争夺 SDK 的内部资源。如果某个 Group 流量特别大，那么势必对其他 Group 造成挤压，导致小流量 Group 无法获得资源。 在 1.10.0 版本中，DataProxy C++ SDK 支持 Custer 以及 Group 级别的资源隔离，用户可以通过配置 enable_isolation 来开启或关闭。感谢 @doleyzi 的贡献，详情可见 INLONG-9213。
<img loading="lazy" alt="1.10.0-sdk-isolation.png" src="/zh-CN/assets/images/1.10.0-sdk-isolation-eaa5c499569e4ebd5077d19f4adc9e77.png" width="1500" height="791" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="实时同步支持配置-transform">实时同步支持配置 Transform<a href="#实时同步支持配置-transform" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 1.10.0 版本中，实时同步任务支持配置 Transform。用户可以在新建实时同步任务时点击设置 Transform 按钮进行配置。目前 Transform 支持两类动作：保留或去除匹配数据、支持复杂过滤规则，在后续版本中，Transform 的能力会不断完善。感谢 @Bluewang 、 @fuwen11 以及 @EMSnap 的贡献， 详情可看 INLONG-8992。
<img loading="lazy" alt="1.10.0-transform.png" src="/zh-CN/assets/images/1.10.0-transform-5a9065517a33f2b14d6a54e25152523c.png" width="1500" height="788" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="未来规划">未来规划<a href="#未来规划" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>在 1.10.0 版本中，社区重构了 InLong Agent，丰富 Flink 1.15 Connector ，完成支持查看操作日志等功能。在后续的版本中，InLong 将继续丰富 Flink 1.15 Connector 、丰富 Transform 能力、统一 DataProxy 数据协议、支持入 Apache Paimon、Dashboard 体验优化等，期待更多开发者参与贡献。</p>]]></content>
        <author>
            <name>Verne Deng</name>
            <uri>https://github.com/vernedeng</uri>
        </author>
        <category label="Apache InLong" term="Apache InLong"/>
        <category label="Version" term="Version"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[1.9.0 版本发布]]></title>
        <id>https://inlong.apache.org/zh-CN/blog/2023/09/25/release-1.9.0</id>
        <link href="https://inlong.apache.org/zh-CN/blog/2023/09/25/release-1.9.0"/>
        <updated>2023-09-25T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Apache InLong（应龙） 最近发布了 1.9.0 版本，该版本关闭了约 200+ 个issue，包含 2+ 个大特性和 30+ 个优化，主要完成了可观测性能力建设、优化DataProxySDK-CPP等。1.9.0 发布后，Apache InLong 在全链路跟踪、指标采集、接入及可视化观测、告警方面补齐了可观测能力建设，解决在开发和运营过程中的快速排查问题、性能优化等需求，优化Apache InLong运营运维的使用体验。]]></summary>
        <content type="html"><![CDATA[<p>Apache InLong（应龙） 最近发布了 1.9.0 版本，该版本关闭了约 200+ 个issue，包含 2+ 个大特性和 30+ 个优化，主要完成了可观测性能力建设、优化DataProxySDK-CPP等。1.9.0 发布后，Apache InLong 在全链路跟踪、指标采集、接入及可视化观测、告警方面补齐了可观测能力建设，解决在开发和运营过程中的快速排查问题、性能优化等需求，优化Apache InLong运营运维的使用体验。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="关于-apache-inlong">关于 Apache InLong<a href="#关于-apache-inlong" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>作为业界首个一站式、全场景海量数据集成框架，Apache InLong（应龙） 提供了自动、安全、可靠和高性能的数据传输能力，方便业务快速构建基于流式的数据分析、建模和应用。目前 InLong 正广泛应用于广告、支付、社交、游戏、人工智能等各个行业领域，服务上千个业务，其中高性能场景数据规模超百万亿条/天，高可靠场景数据规模超十万亿条/天。</p><p>InLong 项目定位的核心关键词是“一站式”、“全场景”和“海量数据”。对于“一站式”，我们希望屏蔽技术细节、提供完整数据集成及配套服务，实现开箱即用；对于“全场景”，我们希望提供全方位的解决方案，覆盖大数据领域常见的数据集成场景；对于“海量数据”，我们希望通过架构上的数据链路分层、全组件可扩展、自带多集群管理等优势，在百万亿条/天的基础上，稳定支持更大规模的数据量。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="190-版本总览">1.9.0 版本总览<a href="#190-版本总览" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>Apache InLong（应龙） 最近发布了 1.9.0 版本，该版本关闭了约 200+ 个 issue ，包含 5+ 个大特性和 30+ 个优化，主要完成了可观测性能力建设、优化 DataProxy C++ SDK、DataProxy 元数据配置更新优化、TubeMQ 增加命令行工具、Iceberg 自动切换写入方式、Manager 支持资源在租户间迁移等。1.9.0 发布后，Apache InLong 在全链路跟踪、指标采集、接入及可视化观测、告警方面补齐了可观测能力建设，解决在开发和运营过程中的快速排查问题、性能优化等需求，同时优化 Apache InLong 运营运维的使用体验。</p><p>Apache InLong 1.9.0 版本中，还完成了大量其它特性，主要包括：</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-模块">Agent 模块<a href="#agent-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持全链路日志跟踪上报，提升可观测性能力</li><li>移除 TaskManager 初始化时的指标上报注销逻辑</li><li>移除设置黑名单的容量限制</li><li>优化 Agent 的 JVM 参数</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dataproxy-模块">DataProxy 模块<a href="#dataproxy-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>优化元数据更新逻辑；</li><li>优化DataProxy指标统计</li><li>优化发送失败后的重发逻辑</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-模块">Sort 模块<a href="#sort-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>数据同步支持审计指标上报</li><li>Iceberg 支持动态切换 append 和 upsert 模式</li><li>数据写入 Kafka 时支持根据定制化字段写入不同分区</li><li>PostgreSQL 支持多并发读取 </li><li>Doris 写入支持 Schema 自动变更</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-模块">Manager 模块<a href="#manager-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持全链路日志跟踪上报，提升可观测性能力</li><li>支持 Tencent CLS、Pulsar 集群、Iceberg 、StartRocks 等数据目标</li><li>在 Flink 1.15上支持 Iceberg 、StarRocks 作为数据源</li><li>完善多租户能力：包括删除租户前支持校验租户状态、OpenAPI 支持租户参数、数据源支持多租户配置等</li><li>ManagerClient 支持分页查询数据流的 Source 和 Sink 资源</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dashboard-模块">Dashboard 模块<a href="#dashboard-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持 Pulsar 数据集群的管理，并支持接出 Pulsar 接出</li><li>优化租户的权限查询性能</li><li>优化界面展现的易用性</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="audit模块">Audit模块<a href="#audit模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>添加 audit_tag 信息以区分数据源和数据目标</li><li>优化审计 Proxy 的日志输出</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sdk模块">SDK模块<a href="#sdk模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>优化 DataProxy C++ SDK，提升性能和网络不稳定时的可靠性</li><li>Sort SDK 支持并行创建缓存层消费</li><li>优化 DataProxy Java SDK 的失败重试策略，以及缓存池和异步发送逻辑</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="tubemq模块">TubeMQ模块<a href="#tubemq模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>增加 TubeMQ 命令行工具</li><li>TubeMQ Manager 增加 restart 脚本</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="其它">其它<a href="#其它" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>增加 ASF DOAP 文件</li><li>增加 MySQL Connector 管理镜像</li><li>优化第三方依赖，解决安全风险</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="190-版本特性介绍">1.9.0 版本特性介绍<a href="#190-版本特性介绍" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="可观测性能力建设">可观测性能力建设<a href="#可观测性能力建设" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 Apache InLong 的应用过程中，经常遇到如下场景需求：</p><ul><li>通过详细的链路调用数据定位到出现问题的代码 ( Tracing )</li><li>对异常模块以及关联日志进行查询分析，找到核心的报错信息 ( Logs )</li><li>打开监控大盘查找异常现象，并通过查询找到异常模块（ Metrics ）</li><li>通过各式各样预设报警发现异常（ Metrics/Logs ）</li></ul><p>在 1.9.0 版本中，@ZhaoNiuniu 基于 OpenTelemetry 完整贡献了 InLong 的可观测性能力建设。OpenTelemetry 提供了灵活、方便和丰富的 Span 定制能力，如添加自定义属性、添加事件等，只需在代码中核心位置进行埋点，就能展示在后端 UI 统一展示 。整个方案主要包括以下几个步骤：</p><ul><li>应用将埋点采集的 Trace、Log、Metric 数据通过 otlp-exporter push 到 otel collector；</li><li>Otel Collector 将数据收集、转换后，导出到 Jaeger 、Prometheus 、Elasticsearch ；</li><li>Grafana 配置三方数据源，统一展示、查询、监控、告警；</li></ul><p><img loading="lazy" alt="1.9.0-observability.png" src="/zh-CN/assets/images/1.9.0-observability-5e36d4e44ea55c85bcfc87239b0f004f.png" width="1500" height="608" class="img_ev3q"></p><p>感谢 @ZhaoNiuniu 的贡献，详情可见 INLONG-8611 和 INLONG-8799 。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dataproxy-c-sdk-优化">DataProxy C++ SDK 优化<a href="#dataproxy-c-sdk-优化" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>老版本 DataProxy C++ SDK 基于 C 语言开发，扩展受限，采用单例模式导致性能受限，对于发送失败场景处理不合理，容易触发 coredump 。因此对 SDK 进行了优化，优化点如下：</p><ul><li>采用 C++ 的开发模式，重构 DataProxy C++ SDK，不用再受C语言限制，增强了代码的扩展性；</li><li>单进程支持多 SDK 实例，支持通过增加 SDK 实例进行水平扩容，突破性能上限；</li><li>数据接收与数据发送进行解耦，可按配置分别增加接收和发送的线程数，提高了 SDK 的可扩展性；</li><li>将 SDK 数据打包逻辑与业务线程进行解耦，一方面减少了对业务线程的影响，另一方面提高了打包的性能；</li><li>从根源上解决了老版本 SDK 发送失败导致 coredump 的问题。</li></ul><p><img loading="lazy" alt="1.9.0-dataproxycplussdk.png" src="/zh-CN/assets/images/1.9.0-dataproxycplussdk-b3babf4ae87ac01754f1a54483b8eb4a.png" width="1500" height="411" class="img_ev3q"></p><p>感谢 @doleyzi 的完整贡献，详情可见 INLONG-8747 。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dataproxy-元数据配置更新优化">DataProxy 元数据配置更新优化<a href="#dataproxy-元数据配置更新优化" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>DataProxy 从 Manager 获取元数据配置，有时会因为网络、误操作等原因，导致 DataProxy 从 Manager 拿到错误的元数据配置，1.9.0 版本 DataProxy 增加了元数据配置更新的保护机制，提升 Apache InLong 在极端场景下的可靠性。感谢 @gosonzhang 的贡献，详情可见 INLONG-8758 和 INLONG-8899 。元数据配置更新的保护机制逻辑如下：</p><p><img loading="lazy" alt="1.9.0-dataproxymetadataupdate.png" src="/zh-CN/assets/images/1.9.0-dataproxymetadataupdate-0c8dd3ec82c2555493b9c9fdc97022cb.png" width="1500" height="375" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="tubemq-增加命令行工具">TubeMQ 增加命令行工具<a href="#tubemq-增加命令行工具" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>为了在服务器管理和 DevOps 场景下，Apache InLong 运维人员可以简单、快速、灵活地在终端窗口中执行各种操作。TubeMQ 提供命令行工具通过命令行参数或选项来管理主题，生产和消费消息，以及管理消费者组。感谢 @fancycoderzf 的贡献，详情可见 INLONG-4972 。详细使用文档，可以参考 <a href="https://inlong.apache.org/docs/modules/tubemq/commandline_tools/" target="_blank" rel="noopener noreferrer">TubeMQ Command-line Tools</a> ，主要功能包括：</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">$ bin/tubectl [options] [command] [command options]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">$ bin/tubectl topic -h</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">$ bin/tubectl message produce</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">$ bin/tubectl message consume</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">$ bin/tubectl cgroup list</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="iceberg-自动切换写入方式">Iceberg 自动切换写入方式<a href="#iceberg-自动切换写入方式" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>目前实时同步 MySQL-&gt; Iceberg 链路全量阶段默认为 upsert 模式，而 upsert 在 Iceberg 中的实现为先 delete 后 add, delete 操作表现为新增 delete 文件，全量阶段会有大量的 delete 文件产生，严重影响了查询的效率。本次优化使得任务能在全量阶段使用 Append 写入，在增量阶段能够自动转为 Upsert 写入。 实现方式源端在数据中携带元数据字段来决定 Iceberg writer 中使用何种方式写入，切换写入方式时会进行数据的刷新，实际写入时去除掉了元数据字段。感谢 <a href="https://github.com/lordcheng10" target="_blank" rel="noopener noreferrer">@lordcheng10</a> 和 @Emsnap 的贡献。</p><p><img loading="lazy" alt="1.9.0-icebergswitch.png" src="/zh-CN/assets/images/1.9.0-icebergswitch-69ebf3849f1eac9efacd5fe0eac3462b.png" width="1411" height="342" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-支持资源在租户间迁移">Manager 支持资源在租户间迁移<a href="#manager-支持资源在租户间迁移" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>InLong 支持多租户后，从旧版本升级上来的 InLong Group 都将被定义在 public 租户下， 用户新建的 InLong Group 则定义在其名下的租户内。这就导致用户需要频繁在多个租户之间切换来使用资源。 本次优化支持 InLong Group 在不同租户之间进行迁移，同时校验并自动创建对应的集群标签， 数据节点等资源。 感谢 @vernedeng 的贡献</p><p><img loading="lazy" alt="1.9.0-managertenant.png" src="/zh-CN/assets/images/1.9.0-managertenant-3cd4b2aa32313c19eabec62be823f41b.png" width="1500" height="203" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="后续规划">后续规划<a href="#后续规划" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>在 1.9.0 版本中，社区还重构 DataProxy C++ SDK ，丰富 Flink 1.15 Connector ，完善数据同步功能等特性。 在后续的版本中，InLong 将继续丰富 Flink 1.15 Connector 、增强数据同步的调度能力、完善 Agent 文件采集能力等，期待更多开发者参与贡献。</p>]]></content>
        <author>
            <name>luchunliang</name>
            <uri>https://github.com/luchunliang</uri>
        </author>
        <category label="Apache InLong" term="Apache InLong"/>
        <category label="Version" term="Version"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[1.8.0 版本发布]]></title>
        <id>https://inlong.apache.org/zh-CN/blog/2023/07/24/release-1.8.0</id>
        <link href="https://inlong.apache.org/zh-CN/blog/2023/07/24/release-1.8.0"/>
        <updated>2023-07-24T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Apache InLong（应龙） 最近发布了 1.8.0 版本，该版本关闭了约 190+ 个issue，包含 6+ 个大特性和 30+ 个优化，主要完成了多租户管理、支持 Apache Flink 多版本、Dashboard 增加数据同步、支持数据预览、优化超长日志处理逻辑等。1.8.0 发布后，Apache InLong 围绕数据接入、数据同步和数据订阅的全场景数据集成布局基本完成，配合多租户管理、多集群管理、审批流管理、全链路审计/指标等。]]></summary>
        <content type="html"><![CDATA[<p>Apache InLong（应龙） 最近发布了 1.8.0 版本，该版本关闭了约 190+ 个issue，包含 6+ 个大特性和 30+ 个优化，主要完成了多租户管理、支持 Apache Flink 多版本、Dashboard 增加数据同步、支持数据预览、优化超长日志处理逻辑等。1.8.0 发布后，Apache InLong 围绕数据接入、数据同步和数据订阅的全场景数据集成布局基本完成，配合多租户管理、多集群管理、审批流管理、全链路审计/指标等。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="关于-apache-inlong">关于 Apache InLong<a href="#关于-apache-inlong" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>作为业界首个一站式、全场景海量数据集成框架，Apache InLong（应龙） 提供了自动、安全、可靠和高性能的数据传输能力，方便业务快速构建基于流式的数据分析、建模和应用。目前 InLong 正广泛应用于广告、支付、社交、游戏、人工智能等各个行业领域，服务上千个业务，其中高性能场景数据规模超百万亿条/天，高可靠场景数据规模超十万亿条/天。</p><p>InLong 项目定位的核心关键词是“一站式”、“全场景”和“海量数据”。对于“一站式”，我们希望屏蔽技术细节、提供完整数据集成及配套服务，实现开箱即用；对于“全场景”，我们希望提供全方位的解决方案，覆盖大数据领域常见的数据集成场景；对于“海量数据”，我们希望通过架构上的数据链路分层、全组件可扩展、自带多集群管理等优势，在百万亿条/天的基础上，稳定支持更大规模的数据量。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="180-版本总览">1.8.0 版本总览<a href="#180-版本总览" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>Apache InLong（应龙） 最近发布了 1.8.0 版本，该版本关闭了约 190+ 个issue，包含 6+ 个大特性和 30+ 个优化，主要完成了多租户管理、支持 Apache Flink 多版本、Dashboard 增加数据同步、支持数据预览、优化超长日志处理逻辑等。1.8.0 发布后，Apache InLong 围绕数据接入、数据同步和数据订阅的全场景数据集成布局基本完成，配合多租户管理、多集群管理、审批流管理、全链路审计/指标等，Apache InLong 搭建完成全方位的数据集成解决方案，实现开箱机用：</p><ul><li>数据接入：数据接入是将数据从数据源汇聚到同一个存储服务的过程，可用于进一步数据查询和分析；</li><li>数据同步：数据同步是建立数据源和目标数据存储之间一致性的过程，可随着时间持续协调数据；</li><li>数据订阅：数据订阅为订阅者提供他们有权访问的数据；</li></ul><p>Apache InLong 1.8.0 版本中，还完成了大量其它特性，主要包括：</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-模块">Agent 模块<a href="#agent-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>优化超长日志处理逻辑，提升文件采集效率和稳定性</li><li>修复因任务停止导致线程泄漏的问题</li><li>采用流量控制，解决文件数增长导致的 OOM 问题</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dataproxy-模块">DataProxy 模块<a href="#dataproxy-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持 Golang SDK</li><li>支持基于完整 IP 或 CIDR 格式的 IP 段配置黑白名单</li><li>支持配置写入最大重试次数</li><li>支持配置写入失败时将数据发送到缺省 Topic</li><li>代码重构，统一配置获取方式</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-模块">Sort 模块<a href="#sort-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>增强了 DDL 的解析能力, 提升 DDL 感知场景的稳定性</li><li>支持 Flink 多版本</li><li>整库场景下支持 Decimal 的精度识别</li><li>Hive 支持整库迁移，实现方式与 mysql 整库迁移保持一致</li><li>Iceberg 支持自动列更新和列删除，极大丰富了 Schema 变更能力</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-模块">Manager 模块<a href="#manager-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持 Pulsar、TubeMQ 数据预览</li><li>支持动态配置审计数据源</li><li>支持查询审计延迟信息</li><li>支持多租户管理</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dashboard-模块">Dashboard 模块<a href="#dashboard-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持流向数据预览</li><li>支持 InLongGroup 查看资源详情</li><li>支持租户管理和租户切换</li><li>支持数据同步</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="其它">其它<a href="#其它" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>移除 Jsqlparser 冲突版本</li><li>升级 Spring-Boot-Autoconfigure 版本到 2.6.15</li><li>升级 Snappy-Java 版本到 1.1.10.1</li><li>修复 Workflow 配置文件语法错误</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="180-版本特性介绍">1.8.0 版本特性介绍<a href="#180-版本特性介绍" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-优化超长日志处理逻辑提升文件采集效率和稳定性">Agent 优化超长日志处理逻辑，提升文件采集效率和稳定性<a href="#agent-优化超长日志处理逻辑提升文件采集效率和稳定性" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在实际使用中，由于用户使用不当或数据生产程序 bug 等问题，偶发出现单条数据长度达到 MB 甚至 GB 级别。 对于部署在低配环境的 Agent 而言，这类数据极大影响了发送的性能。 低版本 Agent 根据换行符将这类数据直接读到内存中再丢弃，但受限于 Agent 部署环境硬件配置， 单条超长数据极易导致 OOM 异常。 在 1.8.0 版本中， Agent 优化了超长日志的处理逻辑， 通过分段采集、分段丢弃的方式保证数据加载不会超过内存限制。 感谢 @justinhuang 的贡献，详情可见 INLONG-8180。
<img loading="lazy" alt="1.8.0-agent-under-1.8.0.png" src="/zh-CN/assets/images/1.8.0-agent-under-1.8.0-9125fe37a0229a983fe1e6f5a6606d31.png" width="2544" height="1356" class="img_ev3q">
<img loading="lazy" alt="1.8.0-agent-1.8.0.png" src="/zh-CN/assets/images/1.8.0-agent-1.8.0-5605736e061b6d7909be88085fe7e328.png" width="3334" height="2143" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-采用全局流控解决文件数增长导致的-oom-问题">Agent 采用全局流控，解决文件数增长导致的 OOM 问题<a href="#agent-采用全局流控解决文件数增长导致的-oom-问题" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在之前版本中，每个文件分别由各自的线程负责采集和发送。虽然我们限制了每个文件的最大采集 buffer，但是随着用户流量的增长，文件数的增加难以避免，进而导致同时采集文件数过多，打爆内存引发 OOM 异常。InLong 在 1.8.0 版本中支持 Agent 配置全局流量控制的特性，利用该特性，Agent 可以有效避免因为文件数增长或者采用小配额服务器导致的频繁 OOM 的问题，感谢 @justinhuang 的贡献，详情可见 INLONG-8251。如果需要使用该特性，可以在 agent.properties 中增加相应配置。
<img loading="lazy" alt="1.8.0-agent-flow-control.png" src="/zh-CN/assets/images/1.8.0-agent-flow-controll-586153f2b9ee526b805dd01af8db56f1.png" width="3356" height="1213" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持-flink-多版本">支持 Flink 多版本<a href="#支持-flink-多版本" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>随着社区用户的深入使用，InLong 面对的场景也更加多样化和复杂化。为了支持不同 Flink 环境的用户需求，InLong 在当前版本增加了支持 Flink 多版本的特性，用户可以在 InLong-Manager 的 plugins/flink-sort-plugin.properties 配置文件中选择启动的flink 版本。</p><p>更换运行 Sort 组件所需要的 Flink 版本时，也需要更换 InLong-Sort/connector 目录中的 connectors 为对应版本的 jar 包，详情可以查看 InLong 官网文档。感谢 @Emsnap，@GanfengTan 和 @haifxu 对该能力的贡献。</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># inLong-manager/plugins/flink-sort-plugin.properties</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Flink version, support [1.13|1.15]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">flink.version=1.13</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持多租户管理">支持多租户管理<a href="#支持多租户管理" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>为了解决多用户场景下对于权限和资源隔离性的要求，InLong 在当前版本引入了多租户架构。多租户架构能够在同一组服务下，确保不同用户间数据和权限互不干扰。感谢 @vernedeng 和 @bluewang 对该功能的贡献，特性详情可见 INLONG-7914。下图为核心流程：
<img loading="lazy" alt="1.8.0-multi-tenant-management.png" src="/zh-CN/assets/images/1.8.0-multi-tenant-management-c3af4313025cdb26d7601e45b2274420.png" width="2597" height="3891" class="img_ev3q"></p><p>租户对于核心逻辑开发者而言是透明的。在请求的入口处，增加了租户鉴权，对于没有访问该租户权限的请求直接驳回；在访问 Database 前，增加对应的租户过滤条件，确保数据的查询和修改范围被限制在该租户内。</p><p>用户可以在 Dashboard 上完成租户的创建，租户角色分配等操作。
<img loading="lazy" alt="1.8.0-create-tenant.png" src="/zh-CN/assets/images/1.8.0-create-tenant-0bddece982572c7109ab72d18431d5c2.png" width="3434" height="1790" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持实时同步">支持实时同步<a href="#支持实时同步" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>新版本中支持了数据的实时同步，实时同步与数据接入的主要区别是不需要中间 MQ 存储的支持，由 Sort 组件直接将源端数据入库，极大丰富了用户的使用场景。</p><p>如下图所示，Tab 页新增 “数据同步” 标签，用户配置完基本 Group 信息后只需要输入 “数据来源” 以及 “数据目标” 信息即可，提交任务后便可实现数据的实时同步。</p><p>感谢 @fuwen11 、@bluewang 、@Emsnap 、@haifxu 对此功能的贡献。
<img loading="lazy" alt="1.8.0-realtime-sync.png" src="/zh-CN/assets/images/1.8.0-realtime-sync-dff9bc08b12b5b1dd6f1573daae1f60f.png" width="3406" height="1730" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持数据预览">支持数据预览<a href="#支持数据预览" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>对于刚接入 InLong 的业务而言，数据预览能够帮助用户快速确认上报数据的准确性以及定位问题。在该版本中，InLong 前端支持预览用户实时上报的数据。感谢 @fuwen11 和 @bluewang 的贡献，用户在成功创建数据流并上报数据后，可以在数据流下的操作栏选择数据预览。
<img loading="lazy" alt="1.8.0-data-preview.png" src="/zh-CN/assets/images/1.8.0-data-preview-b57375e0fb1900ce7ec00e64aadade27.png" width="3454" height="1892" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持查询链路传输时延">支持查询链路传输时延<a href="#支持查询链路传输时延" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>传输时延对于某些实时消费场景至关重要。在该版本中，InLong 审计支持前端查看平均传输时延指标。感谢 @fuwen11 和 @bluewang 的贡献，用户在成功创建数据流并上报数据后， 可以查询链路传输时延。
<img loading="lazy" alt="1.8.0-trans-delay.png" src="/zh-CN/assets/images/1.8.0-trans-delay-43848139f9890a2467bf813425069b40.png" width="3418" height="1920" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="后续规划">后续规划<a href="#后续规划" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>在 1.8.0 版本中，社区还重构了 DataProxy 代码，统一了配置拉取接口，支持完整 IP 和基于 CIDR 的 IP 段配置黑白名单的特性，提升了模块性能和稳定性。 Sort 在 DDL 感知场景的稳定性有所提升， 同时支持 Hive 整库迁移， Iceberg 自动列更新和列存储等特性。 在后续的版本中，InLong 将重构 DataProxy C++ SDK、丰富 Flink 1.15 Connector、完善数据同步功能等，期待更多开发者参与贡献。</p>]]></content>
        <author>
            <name>Verne Deng</name>
            <uri>https://github.com/vernedeng</uri>
        </author>
        <category label="Apache InLong" term="Apache InLong"/>
        <category label="Version" term="Version"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[1.7.0 版本发布]]></title>
        <id>https://inlong.apache.org/zh-CN/blog/2023/05/19/release-1.7.0</id>
        <link href="https://inlong.apache.org/zh-CN/blog/2023/05/19/release-1.7.0"/>
        <updated>2023-05-19T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Apache InLong（应龙） 最近发布了 1.7.0 版本，该版本关闭了约 150+ 个issue，包含 3+ 个大特性和 40+ 个优化。主要完成了支持直发数据到 Kafka、MySQL 整库迁移支持 schema 变更、MySQL 整库迁移支持 GH-OST 感知、增加 CSV/SQL/JSON/Excel 4 种批量导入模式、简化命令行工具创建数据流配置、重构 Dashboard 整体布局等。]]></summary>
        <content type="html"><![CDATA[<p>Apache InLong（应龙） 最近发布了 1.7.0 版本，该版本关闭了约 150+ 个issue，包含 3+ 个大特性和 40+ 个优化。主要完成了支持直发数据到 Kafka、MySQL 整库迁移支持 schema 变更、MySQL 整库迁移支持 GH-OST 感知、增加 CSV/SQL/JSON/Excel 4 种批量导入模式、简化命令行工具创建数据流配置、重构 Dashboard 整体布局等。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="关于-apache-inlong">关于 Apache InLong<a href="#关于-apache-inlong" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>作为业界首个一站式开源海量数据集成框架，Apache InLong（应龙） 提供了自动、安全、可靠和高性能的数据传输能力，方便业务快速构建基于流式的数据分析、建模和应用。目前 InLong 正广泛应用于广告、支付、社交、游戏、人工智能等各个行业领域，服务上千个业务，其中高性能场景数据规模超百万亿条/天，高可靠场景数据规模超十万亿条/天。</p><p>InLong 项目定位的核心关键词是“一站式”和“海量数据”。对于“一站式”，我们希望屏蔽技术细节、提供完整数据集成及配套服务，实现开箱即用；对于“海量数据”，我们希望通过架构上的数据链路分层、全组件可扩展、自带多集群管理等优势，在百万亿条/天的基础上，稳定支持更大规模的数据量。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="170-版本总览">1.7.0 版本总览<a href="#170-版本总览" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>Apache InLong（应龙） 最近发布了 1.7.0 版本，该版本关闭了约 150+ 个issue，包含 3+ 个大特性和 40+ 个优化。主要完成了支持直发数据到 Kafka、MySQL 整库迁移支持 schema 变更、MySQL 整库迁移支持 GH-OST 感知、增加 CSV/SQL/JSON/Excel 4 种批量导入模式、简化命令行工具创建数据流配置、重构 Dashboard 整体布局等。该版本还完成了大量其它特性，主要包括：</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-模块">Agent 模块<a href="#agent-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持直接发送数据到 Kafka，不经过 DataProxy</li><li>Agent 优化，提供文件采集发性能</li><li>修复 MySQL 采集时 Reader 创建失败问题</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dataproxy-模块">DataProxy 模块<a href="#dataproxy-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>简化 common 配置及相关控制逻辑</li><li>代码优化，清理 ConfigManager 中的无效配置</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-模块">Manager 模块<a href="#manager-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>增加 PostgreSQL、Redis 数据节点管理</li><li>为数据源增加心跳超时状态</li><li>增加 CSV/SQL/JSON/Excel 4 种批量导入模式</li><li>简化命令行工具，涉及数据流创建的逻辑</li><li>支持重启和停止数据流中的数据源任务</li><li>Redis、Kudu 增加连接性测试</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-模块">Sort 模块<a href="#sort-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>在日志中屏蔽 Flink SQL 相关数据源/目标端的敏感信息</li><li>优化计算对象字节大小的逻辑及相关指标</li><li>支持在原始数据中提取 DDL 及操作</li><li>写入 Iceberg 时增加速率控制</li><li>MySQL 整库迁移支持 schema 变更</li><li>整库迁移中，MySQL Connector 支持感知 GH-OST 的 DDL</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dashboard-模块">Dashboard 模块<a href="#dashboard-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>增加 CSV/SQL/JSON/Excel 4 种批量导入页面</li><li>优化 Clickhouse 流向配置，支持 ttl/engine 等配置</li><li>重构 Dashboard 整体布局，优化显示体验</li><li>优化数据源和数据目标端创建流程</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="其它">其它<a href="#其它" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>修复多个 MySQL 相关安全漏洞</li><li>TubeMQ Golang SDK 支持生产，完成一期开发</li><li>优化 InLong 开发工具在 MacOS 和 Linux 的支持</li><li>优化 Pulsar Client 依赖减小安装包大小</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="170-版本特性介绍">1.7.0 版本特性介绍<a href="#170-版本特性介绍" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持直发数据到-kafka">支持直发数据到 Kafka<a href="#支持直发数据到-kafka" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在之前版本中，InLong 支持了 Agent 直发数据到 Pulsar 而不经过 DataProxy，通过这样的设计，对于数据场景简单、尽可能保证数据完整性用户，可以减少对 DataProxy 的依赖。对于习惯使用 Kafka 的用户，在 1.7.0 版本中支持了 Agent 直发数据到 Kafka 的特性，感谢 @wangpeix 的完整贡献，详情可见 INLONG-7783。如果需要体验该特性，可以在数据流审批环节选择“发往 MQ，待 MQ 接收后再响应”。</p><p><img loading="lazy" alt="1.7.0-kafka-stream" src="/zh-CN/assets/images/1.7.0-kafka-stream-160a6bb1039f6528b6fe35127f5144f5.png" width="796" height="306" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="mysql-整库迁移支持-schema-变更">MySQL 整库迁移支持 schema 变更<a href="#mysql-整库迁移支持-schema-变更" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>随着社区用户对 InLong 的深入使用，不能支持 schema 变更的弊端逐渐显现，源端变更 DDL 后需要任务修改配置重启，大大增大了运维成本，在当前版本中，InLong 支持了 schema 的自动变更能力，上游数据源支持感知 Create、Alter、Drop、Truncate、Rename 等 DDL 操作，并同步该 DDL 操作到下游，同时下游数据源支持响应上游 DDL 变更，并同步处理该 DDL 变更，同时支持不同处理策略，详情参考 INLONG-7553。感谢 @Emsnap @yunqingmoswu @lordcheng10 对该功能的贡献，下图为核心流程：</p><p><img loading="lazy" alt="1.7.0-mysql-schema" src="/zh-CN/assets/images/1.7.0-mysql-schema-a2fa0fd42333476bceec44d1f5f7346b.png" width="1500" height="528" class="img_ev3q"></p><p>数据库中的 DDL 消息由 CDC 中的 DEBEZIUM 感知，此时得到的数据为单一的 DDL 语句，例如：“DROP TABLE A”，该语句为 DEBEZIUM JSON 中的字段，DDL 语句后经由 JSQLPARSER 解析为 DDL MODEL，该 MODEL 中对常见的 DDL 消息都进行了解析，处理为程序易处理的 JSON 格式，DDL MODEL 会作为 FLINK 中的数据下发到 SINK OPERATOR, 由 OPERATOR 对 DDL MODEL 进行处理。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="mysql-整库迁移支持-gh-ost-感知">MySQL 整库迁移支持 GH-OST 感知<a href="#mysql-整库迁移支持-gh-ost-感知" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>GH-OST（GitHub Online Schema Migration）是 GitHub 发布的一款用于 MySQL 的无触发器在线模式迁移解决方案。它是可测试的，并提供暂停，动态控制/重新配置，审计和许多操作特权。它在整个迁移过程中，对主服务器产生的工作量很少，与已迁移表上的现有工作分离。通过支持感知 GH-OST 的 DDL，MySQL Connector 可以在捕获数据变更的同时，正确处理由 GH-OST 引发的表结构变更。感谢 @e-mhui 的完整贡献，该特性详情可见 INLONG-7554。下图为核心流程：</p><p><img loading="lazy" alt="1.7.0-mysql-ghost" src="/zh-CN/assets/images/1.7.0-mysql-ghost-c636b0dc81e758f18e5b73e00701bbe8.png" width="1500" height="1099" class="img_ev3q"></p><p>首先，开启 MySQL CDC 的 DDL 自动响应后，对 GH-OST 产生的 ghc, gho, del 表也进行捕获；其次，在感知到 GH-OST 对 gho 表的变更时，将 DDL 语句中的 gho 表替换成 源表，并存储到 state 中；最后，在 GH-OST 对源表执行完整的变更流程后，将之前存储到 state 中的 DDL 语句发送到下游。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="增加-csvsqljsonexcel-4-种批量导入模式">增加 CSV/SQL/JSON/Excel 4 种批量导入模式<a href="#增加-csvsqljsonexcel-4-种批量导入模式" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在创建数据流录入元数据字段时，我们需要按名称、类型、描述等信息依次输入，如果需要录入成百上千的字段信息，这种处理方式效率极低。在 1.7.0 版本中，InLong 同时增加了 CSV/SQL/JSON/Excel 4 种格式的批量导入模式，用户只需要参考每种格式的模板，填写自选信息，就可以实现一次性导入。该功能非常感谢 @featzhang、@fuweng11 参与开发完成。4 种批量导入模式已经支持前后端，可下载最新版本直接使用。</p><p><img loading="lazy" alt="1.7.0-batch-add" src="/zh-CN/assets/images/1.7.0-batch-add-136b87483c01a78bbbd7b80aa194ea9b.png" width="643" height="874" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="简化命令行工具创建数据流配置">简化命令行工具创建数据流配置<a href="#简化命令行工具创建数据流配置" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>旧版本使用命令行创建数据流时，需要准备的 JSON 文件内容很复杂，并且文件结构不够清晰，用户通过命令行创建数据流的门槛非常高。另外，用户想复用文件创建新的数据流时，需要修改很多重复的字段，如 inlongGroupID、inlongStreamID。在 1.7.0 版本中，InLong 优化了数据流配置 JSON 结构以及字段配置，用户可根据数据流需求，简单添加 Source / Sink 内容即可，整个创建数据流过程相较之前简单了很多。详情可见 INLONG-7778，非常感谢 @haifxu 的贡献。以下示例为新版本创建 File -&gt; Pulsar -&gt; Clickhouse 的模板：</p><div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token property">"groupInfo"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token property">"inlongGroupId"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"test_group_ctl"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token property">"inlongClusterTag"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"default_cluster"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token property">"mqType"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"PULSAR"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token property">"streamInfo"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token property">"inlongStreamId"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"test_stream_ctl"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token property">"fieldList"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token property">"fieldName"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"name"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token property">"fieldType"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"string"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token property">"sourceList"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token property">"sourceType"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"FILE"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token property">"sourceName"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"test_source_ctl"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token property">"agentIp"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"127.0.0.1"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token property">"pattern"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"/data/test.txt"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token property">"sinkList"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token property">"sinkType"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"CLICKHOUSE"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token property">"sinkName"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"test_sink_ctl"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token property">"dataNodeName"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"test_clickhouse"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token property">"dbName"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"db_test"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token property">"tableName"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"table_test"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token property">"flushInterval"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token property">"flushRecord"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token number">1000</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token property">"retryTimes"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token number">3</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token property">"engine"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"Log"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token property">"isDistributed"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token property">"sinkFieldList"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        </span><span class="token property">"sourceFieldName"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"name"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        </span><span class="token property">"sourceFieldType"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"string"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        </span><span class="token property">"fieldName"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"name"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        </span><span class="token property">"fieldType"</span><span class="token operator">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"string"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="重构-dashboard-整体布局">重构 Dashboard 整体布局<a href="#重构-dashboard-整体布局" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 1.7.0 版本中，社区重构了 Dashboard 的整体布局，包括将上下布局调整为左右布局（导航栏移动到左侧）、增加暗黑主题、主要菜单增加 icon、调整数据源选择显示和流程等，这次调整使 Dashboard 的使用体验更好，特别感谢@leezng、@bluewang 的贡献，详情可见 INLONG-7734。</p><p><img loading="lazy" alt="1.7.0-dashboard-refactor" src="/zh-CN/assets/images/1.7.0-dashboard-refactor-e7c82a297e6b8bbb8dace6e13436493a.png" width="1500" height="414" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="后续规划">后续规划<a href="#后续规划" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>在 1.7.0 版本中，社区还提升了 Agent 文件采集的性能和稳定性，同时 TubeMQ 完成 Golang SDK 生产一期，Sort 也能够使用 Manager 分配的订阅组进行消费。在后续的版本中，InLong 会支持 Apache Flink 多版本，除了当前的 Flink 1.13，还会支持 Flink 1.15；另外，也会增加租户管理，完成 InLong 项目、用户、资源的模型的统一，期待更多开发者参与贡献。</p>]]></content>
        <author>
            <name>Charles Zhang</name>
            <uri>https://github.com/dockerzhang</uri>
        </author>
        <category label="Apache InLong" term="Apache InLong"/>
        <category label="Version" term="Version"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[1.6.0 版本发布]]></title>
        <id>https://inlong.apache.org/zh-CN/blog/2023/03/23/release-1.6.0</id>
        <link href="https://inlong.apache.org/zh-CN/blog/2023/03/23/release-1.6.0"/>
        <updated>2023-03-23T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Apache InLong（应龙） 最近发布了 1.6.0 版本，该版本关闭了约 202+ 个issue，包含 9+ 个大特性和 80+ 个优化。主要完成了新增 Kudu 数据流向、完善 Redis 数据流向、增加 MQ 缓存集群 Selector 策略、优化 Audit ID 分配规则、新增数据节点链接性测试、优化 Sort Audit 对账基准时间、Audit 支持使用 Kafka 缓存审计数据等。]]></summary>
        <content type="html"><![CDATA[<p>Apache InLong（应龙） 最近发布了 1.6.0 版本，该版本关闭了约 202+ 个issue，包含 9+ 个大特性和 80+ 个优化。主要完成了新增 Kudu 数据流向、完善 Redis 数据流向、增加 MQ 缓存集群 Selector 策略、优化 Audit ID 分配规则、新增数据节点链接性测试、优化 Sort Audit 对账基准时间、Audit 支持使用 Kafka 缓存审计数据等。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="关于-apache-inlong">关于 Apache InLong<a href="#关于-apache-inlong" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>作为业界首个一站式开源海量数据集成框架，Apache InLong（应龙） 提供了自动、安全、可靠和高性能的数据传输能力，方便业务快速构建基于流式的数据分析、建模和应用。目前 InLong 正广泛应用于广告、支付、社交、游戏、人工智能等各个行业领域，服务上千个业务，其中高性能场景数据规模超百万亿条/天，高可靠场景数据规模超十万亿条/天。</p><p>InLong 项目定位的核心关键词是“一站式”和“海量数据”。对于“一站式”，我们希望屏蔽技术细节、提供完整数据集成及配套服务，实现开箱即用；对于“海量数据”，我们希望通过架构上的数据链路分层、全组件可扩展、自带多集群管理等优势，在百万亿条/天的基础上，稳定支持更大规模的数据量。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="160-版本总览">1.6.0 版本总览<a href="#160-版本总览" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>Apache InLong（应龙） 最近发布了 1.6.0 版本，该版本关闭了约 202+ 个issue，包含 9+ 个大特性和 80+ 个优化。主要完成了新增 Kudu 数据流向、增加 MQ 缓存集群级别 Selector 策略、优化 Audit ID 分配规则、新增数据节点链接性测试、优化 Sort 关于 Audit 对账基准时间、Audit 支持使用 Kafka 缓存审计数据等。该版本还完成了大量其它特性，主要包括：</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-模块">Agent 模块<a href="#agent-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>增强文件采集稳定性，修复多个采集 Bug </li><li>修复 MQTT 、MongoDB 等多个 Bug</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dataproxy-模块">DataProxy 模块<a href="#dataproxy-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>增加 MQ 缓存集群 Selector 策略，减少 Producer 数量</li><li>为新的 MQ Sink 增加 Audit 上报</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-模块">Manager 模块<a href="#manager-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>优化 Audit ID 分配规则，支持多 Load 数据节点审计</li><li>优化 ClickHouse 数据节点元数据配置和管理</li><li>新增数据节点链接性测试，检查节点可用性</li><li>增加 Pulsar 多集群 Topic 订阅管理</li><li>修复 Manager 多个数据流管理、状态管理 Bug</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-模块">Sort 模块<a href="#sort-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>为 Kafka Source Connector 新增数据审计</li><li>Doris Connector 新增 CSV 格式及脏数据归档</li><li>支持 ARRAY、MAP、STRUCT 等复杂类型</li><li>优化 Pulsar Connector 解决数据丢失问题</li><li>修复 Canal-JSON 元数据字段乱序写入问题</li><li>优化 Sort 关于 Audit 对账基准时间，对齐对账</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dashboard-模块">Dashboard 模块<a href="#dashboard-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>持续优化 Dashboard 体验，降低初次部署理解门槛</li><li>增加 Redis、Kudu 等数据节点管理</li><li>优化 PostgreSQL 、Kafka、Redis 等数据节点参数</li><li>简化 Agent 节点 IP 选取策略</li><li>增加多个数据节点链接性测试页面</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="其它">其它<a href="#其它" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>Audit 支持使用 Kafka 缓存审计数据</li><li>Audit 统一从 Manager 获取 MQ 集群</li><li>优化 Standalone、Docker-compose 、Kubernetes 等部署步骤</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="160-版本特性介绍">1.6.0 版本特性介绍<a href="#160-版本特性介绍" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="新增-kudu-数据流向">新增 Kudu 数据流向<a href="#新增-kudu-数据流向" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>Apache Kudu 是由 Cloudera 开源的存储引擎，可以同时提供低延迟的随机读写和高效的数据分析能力。在 1.6.0 版本中， InLong 支持了 Kudu 数据流向，包括新增 Kudu Connector、元数据管理、指标、Dashboard 页面等。Kudu 数据流向由 @featzhang 独立参与和完整贡献，感兴趣的用户可以进行安装体验。
<img loading="lazy" alt="1.6.0-create-kudu" src="/zh-CN/assets/images/1.6.0-create-kudu-36e66939d4032f4839fc1b5984b5752e.png" width="1470" height="1031" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="完善-redis-数据流向">完善 Redis 数据流向<a href="#完善-redis-数据流向" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>Redis 是很流行的开源内存数据库，拥有高性能和丰富的数据结构，在 1.6.0 版本， InLong 完善了 Redis 数据流向，包括在 Redis Connector 中增加 SinkFunction、元数据管理、指标和 Dashboard 页面等，完整支持了 Redis 的 Plain、Hash、Bitmap 等数据格式, 并通过 SchemaMapping 机制实现 Redis Schema 转换。Redis 数据流向通过 Schema 映射模式，可以将 Schema 转换为不同的 <a href="https://redis.io/docs/data-types/tutorial/" target="_blank" rel="noopener noreferrer">Redis Data-Type</a>  。 Redis 数据流向主要由 @featzhang 独立参与和完整贡献，详见 <a href="https://github.com/apache/inlong/issues/7060" target="_blank" rel="noopener noreferrer">INLONG-7060</a> 。
<img loading="lazy" alt="1.6.0-update-redis" src="/zh-CN/assets/images/1.6.0-update-redis-017cd2d29c513ca867bfef88f9bf8ea6.png" width="755" height="792" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="增加-mq-缓存集群-selector-策略">增加 MQ 缓存集群 Selector 策略<a href="#增加-mq-缓存集群-selector-策略" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>多 MQ 集群场景下，如果 DataProxy 同时连接所有 MQ 集群，会导致 MQ 集群的 Producer 数暴增，同时导致 Zookeeper 元数据超量，进而引发 OutOfMemory。在 1.6.0 版本中，InLong 增加了 MQ 缓存集群级别 Selector 策略（主要针对 Apache Pulsar），DataProxy 节点可以只选择同一个 Tag 下的部分 MQ 集群进行生产，从而降低 Producer 连接数和 Zookeeper 元数据规模。该特性主要是由 @luchunliang 开发完成，详见 <a href="https://github.com/apache/inlong/pull/7236" target="_blank" rel="noopener noreferrer">INLONG-7231</a> 。
<img loading="lazy" alt="1.6.0-mq-selector" src="/zh-CN/assets/images/1.6.0-mq-selector-80659d1793454422d4f75feaa31eaed7.png" width="1468" height="447" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="优化-audit-id-分配规则">优化 Audit ID 分配规则<a href="#优化-audit-id-分配规则" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 InLong Audit 原有的设计的中，每个模块的接收与发送分别为一个独立的审计项 ID，用于记录模块级别的数据发送和数据接收量。该方案存在一个缺陷，如果 InLong Sort 同时向多个目标端分拣数据（比如同时写入 Hive 和 Clickhouse），那一个审计项 ID 对于 Sort  来说无法区分不同的数据流向。在 1.6.0 版本中，优化了 Audit ID 分配规则，不同的数据流向在 Sort 分拣中拥有不同的审计项 ID，实现了对同个数据流多个分拣目标的数据审计。该特性同时涉及 Manager 和 Sort 的改动，由 @fuweng11 和 @EMsnap 一起开发实现，详见 <a href="https://github.com/apache/inlong/pull/7390" target="_blank" rel="noopener noreferrer">INLONG-7389</a>, <a href="https://github.com/apache/inlong/pull/7233" target="_blank" rel="noopener noreferrer">INLONG-7232</a> 和 <a href="https://github.com/apache/inlong/pull/7552" target="_blank" rel="noopener noreferrer">INLONG-7503</a> 。</p><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">'audit_sort_hive_input'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'HIVE'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'7'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">'audit_sort_hive_output'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'HIVE'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'8'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">'audit_sort_clickhouse_input'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'CLICKHOUSE'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'9'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">'audit_sort_clickhouse_output'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'CLICKHOUSE'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'10'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">'audit_sort_es_input'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'ELASTICSEARCH'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'11'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">'audit_sort_es_output'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'ELASTICSEARCH'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'12'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">'audit_sort_starrocks_input'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'STARROCKS'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'13'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">'audit_sort_starrocks_output'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'STARROCKS'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'14'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">'audit_sort_hudi_input'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'HUDI'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'15'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">'audit_sort_hudi_output'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'HUDI'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'16'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">'audit_sort_iceberg_input'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'ICEBERG'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'17'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">'audit_sort_iceberg_output'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'ICEBERG'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'18'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">'audit_sort_hbase_input'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'HBASE'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'19'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">'audit_sort_hbase_output'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'HBASE'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'20'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">'audit_sort_doris_input'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'DORIS'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'21'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">'audit_sort_doris_output'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'DORIS'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'22'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="新增数据节点链接性测试">新增数据节点链接性测试<a href="#新增数据节点链接性测试" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在之前版本中，InLong 新增数据节点以及注册 MQ 集群，并没有判断集群可用性。在新版本中，InLong 为主要的数据节点及 InLong 系统组件注册，新增了链接性测试，用于提前检查待注册集群，提升数据流创建易用性。该特性主要是由 @leosanqing、@bluewang 和 @fuweng11 参与开发。
<img loading="lazy" alt="1.6.0-connection-test" src="/zh-CN/assets/images/1.6.0-connection-test-ce6b8f02839f8e7cc032a48b2930e95a.png" width="894" height="794" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="优化-sort-audit-对账基准时间对齐对账">优化 Sort Audit 对账基准时间，对齐对账<a href="#优化-sort-audit-对账基准时间对齐对账" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 1.6.0 版本之前，Sort 的对账基准时间是处理数据时的机器时间，使用该时间会造成全链路数据对账不准确。在该版本中，Sort 对账埋点借鉴了 Flink 中的 TimestampedCollector 设计，替换了原有 Pulsar Connector 中的 Simple Collector，对齐了对账指标。实现原理为在 Collector 中设置了 Timestamp 字段，当获取到由 Dataproxy 传输的 InlongMsg 数据时，先对其进行解包并提取包内每条消息的数据时间，对 Collector 中的 Timestamp 进行重置，Collector 在往下游传输消息时将重置后的数据时间作为 Audit 时间记录指标。优化后的 Sort Audit 对账指标能与 DataProxy 等其它模块对齐，该特性主要由 @Emsnap 开发。
<img loading="lazy" alt="1.6.0-sort-audit-time" src="/zh-CN/assets/images/1.6.0-sort-audit-time-7c9f9fab9863e49ab6b5167ebe522e91.png" width="1910" height="893" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="audit-支持使用-kafka-缓存审计数据">Audit 支持使用 Kafka 缓存审计数据<a href="#audit-支持使用-kafka-缓存审计数据" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>InLong Audit 是独立的子系统，对 InLong 系统的 Agent、DataProxy、Sort 模块的入流量、出流量进行实时审计对账，目前对账的粒度有分钟、小时、天三种。在之前的版本中，InLong Audit 只支持使用 Pulsar 缓存审计数据，这里会增加只熟悉 Kafka 的用户部署和使用成本，在整个  InLong Audit 设计上，MQ 类型的选择应该和数据流保持一致，避免使用不同的 MQ 类型。在 1.6.0 版本中，为了实现 Audit 模块和数据流保持使用同类型 MQ 服务，Audit 支持了使用 Kafka 缓存审计数据，实现了 MQ 服务选型的统一。该特性主要是由 @haifxu、@dockerzhang 完成。
<img loading="lazy" alt="1.6.0-audit-kafka" src="/zh-CN/assets/images/1.6.0-audit-kafka-120f70dcf6449309dd9824c5e4d7faa1.png" width="843" height="732" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="后续规划">后续规划<a href="#后续规划" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>在 1.6.0 中，Sort 模块还修复脏数据归档、指标、Connector 等多个 Bug，Dashboard 持续优化显示、审批流程等体验问题，详情可以参考 1.6.0 发布 <a href="https://github.com/apache/inlong/blob/master/CHANGES.md" target="_blank" rel="noopener noreferrer">Changelog</a> 。在后续版本中，Apache  InLong 会增加 Schema 动态感知、Schema 批量导入、Agent 安装、扩展更多数据节点等，期待更多开发者参与贡献。</p>]]></content>
        <author>
            <name>Charles Zhang</name>
            <uri>https://github.com/dockerzhang</uri>
        </author>
        <category label="Apache InLong" term="Apache InLong"/>
        <category label="Version" term="Version"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[1.5.0 版本发布]]></title>
        <id>https://inlong.apache.org/zh-CN/blog/2023/01/13/release-1.5.0</id>
        <link href="https://inlong.apache.org/zh-CN/blog/2023/01/13/release-1.5.0"/>
        <updated>2023-01-13T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Apache InLong（应龙）最近发布了 1.5.0 版本，该版本关闭了约 296+ 个issue，包含 12+ 个大特性和 110+ 个优化。主要完成了新增 StarRocks、Hudi、Doris、Elasticsearch 等流向、优化 Dashboard 体验、重构 MQ 管理模型、新增脏数据处理、全链路 Apache Kafka 支持、TubeMQ C++/Python SDK 支持生产等。]]></summary>
        <content type="html"><![CDATA[<p>Apache InLong（应龙）最近发布了 1.5.0 版本，该版本关闭了约 296+ 个issue，包含 12+ 个大特性和 110+ 个优化。主要完成了新增 StarRocks、Hudi、Doris、Elasticsearch 等流向、优化 Dashboard 体验、重构 MQ 管理模型、新增脏数据处理、全链路 Apache Kafka 支持、TubeMQ C++/Python SDK 支持生产等。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="关于-apache-inlong">关于 Apache InLong<a href="#关于-apache-inlong" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>作为业界首个一站式开源海量数据集成框架，Apache InLong 提供了自动、安全、可靠和高性能的数据传输能力，方便业务快速构建基于流式的数据分析、建模和应用。目前 InLong 正广泛应用于广告、支付、社交、游戏、人工智能等各个行业领域，服务上千个业务，其中高性能场景数据规模超百万亿/天，高可靠场景数据规模超十万亿/天。</p><p>InLong 项目定位的核心关键词是“一站式”和真正“海量数据”。对于“一站式”，我们希望屏蔽技术细节、提供完整数据集成及配套服务，实现开箱即用；对于“海量数据”，我们希望通过架构上的数据链路分层、全组件可扩展、自带多集群管理等优势，在百万亿/天的基础上，稳定支持更大规模的数据量。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="150-版本总览">1.5.0 版本总览<a href="#150-版本总览" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>Apache InLong 最近发布了 1.5.0 版本，该版本关闭了约 296+ 个issue，包含 12+ 个大特性和 110+ 个优化。主要完成了新增 StarRocks、Hudi、Doris、Elasticsearch 等流向、优化 Dashboard 体验、重构 MQ 管理模型、新增脏数据处理、全链路 Apache Kafka 支持、TubeMQ C++/Python SDK 支持生产等。该版本还完成了大量其它特性，主要包括：</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-模块">Agent 模块<a href="#agent-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持 CVM 场景下的日志采集</li><li>新增直发Pulsar、发送 DataProxy 同步异步策略</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dataproxy-模块">DataProxy 模块<a href="#dataproxy-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>重构 MQ 管理模型，支持快速扩展新的 MQ 类型</li><li>优化缓存层支持 Apache Kafka 消息队列</li><li>新增支持 BufferQueueChannel</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="tubemq-模块">TubeMQ 模块<a href="#tubemq-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>增加数据发送和接收延迟统计</li><li>TubeMQ C++ SDK 支持生产</li><li>TubeMQ Python SDK 支持生产</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-模块">Manager 模块<a href="#manager-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>新增 Hudi 数据节点和流向管理</li><li>新增 StarRocks 数据节点和流向管理</li><li>优化 Elasticsearch 数据节点和流向管理</li><li>Manager Client 新增数据转换管理</li><li>优化  Apache Kafka 消息队列管理</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-模块">Sort 模块<a href="#sort-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>MySQL Load 节点存量阶段支持对无主键的表的并发读取</li><li>新增 StarRocks、Hudi、Doris、Elasticsearch 5.x 数据流向支持</li><li>为 Doris、PostgreSQL、Hive、HBase、Elasticsearch 等流向增加脏数据处理</li><li>升级 Iceberg 到 1.1.0 版本</li><li>StarRocks、PostgreSQL、Doris、Hudi 等流向支持表级别指标</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dashboard-模块">Dashboard 模块<a href="#dashboard-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>体验优化超 50 个优化点</li><li>增加 JSON、Key-Value、AVRO 格式</li><li>支持 ClickHouse 、Iceberg、Elasticsearch、MySQL 等数据节点管理页面</li><li>新增 SQLServer 、Oracle 、MongoDB、MQTT 数据源页面</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="其它">其它<a href="#其它" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>增加 Spotless 代码格式化插件及响应流水线</li><li>Docker-compose 自带 Apache Flink 环境</li><li>增加 Agent、DataProxy 的 Grafana 指标显示模板</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="150-版本特性介绍">1.5.0 版本特性介绍<a href="#150-版本特性介绍" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="新增-starrockshudidoriselasticsearch-等流向">新增 StarRocks、Hudi、Doris、Elasticsearch 等流向<a href="#新增-starrockshudidoriselasticsearch-等流向" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 1.5.0 版本中，InLong 持续扩展新的数据节点 Connector，针对社区用户使用场景，新增 StarRocks、Hudi、Doris、Elasticsearch 等流向的支持，拓展了数据入仓入湖场景。这些新增数据节点主要由 @liaorui、@featzhang、@kuansix、@LvJiancheng 等开发者贡献。
<img loading="lazy" alt="1.5.0-create-hudi-source" src="/zh-CN/assets/images/1.5.0-create-hudi-source-d2624fa14bf48794da2729583061f903.png" width="1328" height="1246" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="优化-dashboard-体验">优化 Dashboard 体验<a href="#优化-dashboard-体验" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>相比于传统的数据集成项目，InLong 新增了 Group、Stream 、数据节点等概念，初次使用 Dashboard 创建的社区用户会对整个流程有些困惑。为了降低 Dashboard 用户的使用成本，InLong 针对 Dashboard 前端页面进行了大量的优化，优化点超过 50 个，在概念、流程、展示上面进行了调整。下图为 1.5.0 中创建 Stream 的流程，相比较之前版本更加简化。Dashboard 的优化特别感谢 @leezng、@bluewang、@kinfuy，也感谢 @Charles Zhang 提供的修改建议。
<img loading="lazy" alt="1.5.0-create-dashboard-stream" src="/zh-CN/assets/images/1.5.0-create-dashboard-stream-3c3bb921a77735d2c07e4d568730b093.png" width="1500" height="434" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="重构-mq-管理模型">重构 MQ 管理模型<a href="#重构-mq-管理模型" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>为了快速支持新的消息队列服务（比如 RocketMQ）实现插件化，同时统一现有支持 Pulsar、Kafka、TubeMQ，在 1.5.0 版本中，InLong DataProxy 重构了 MQ 管理模型，所有 MQ 类型都基于 <code>MessageQueueHandler</code> 实现对应的 <code>Handler</code>。该特性的实现感谢 @woofyzhao、@luchunliang，如果需要开发新的 MQ 类型，可以参考 DataProxy 插件指引。
<img loading="lazy" alt="1.5.0-mq-handler" src="/zh-CN/assets/images/1.5.0-mq-handler-de6522ff228c5a35d74e661da04dee25.png" width="959" height="511" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="新增脏数据处理">新增脏数据处理<a href="#新增脏数据处理" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>如果入湖入仓时存在不符合数据规范的脏数据（例如字段范围超限、数据字段缺失等 ），可能会导致用户任务写入失败并不断重启。在 1.5.0 版本中，InLong 支持将不能恢复的脏数据到外部存储，包括 S3 和本地日志，同时用户可以自定义脏数据的输出端，可以配置 “是否开启脏数据归档” 与 “是否忽略写入错误”，如下为脏数据归档设计 UML 图。该特性的实现感谢 @yunqingmoswu、@Yizhou-Yang 的支持。
<img loading="lazy" alt="1.5.0-dirty-data" src="/zh-CN/assets/images/1.5.0-dirty-data-f0d44e031631c4128e14293d7fa0ec01.png" width="1500" height="577" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="全链路-apache-kafka-支持">全链路 Apache Kafka 支持<a href="#全链路-apache-kafka-支持" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 1.5.0 版本中，完成了 DataProxy、Manager、Sort、Dashboard 模块全链路对 Apache Kafka 的支持，对于 kafka 的支持经历了两个版本，在 1.5.0 实现了生产可用，用户创建数据流时选择 Kafka 即可。该特性的实现感谢 @woofyzhao、@fuweng11、@haifxu 的支持。
<img loading="lazy" alt="1.5.0-support-kafka" src="/zh-CN/assets/images/1.5.0-support-kafka-d7c02c918440b48faa62373f2332e6db.png" width="1500" height="482" class="img_ev3q"></p><p>更多 1.5.0 版本的细节请参考 版本说明 ，其中详细列出了此版本的特性、提升和 Bug 修复。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="后续规划">后续规划<a href="#后续规划" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>在后续版本中，Apache  InLong 会增加多租户管理，规范数据流、项目、集群和用户的资源和权限，同时对多种数据源进行性能和稳定性优化、Agent 管理等，期待更多开发者参与贡献。</p>]]></content>
        <author>
            <name>Charles Zhang</name>
            <uri>https://github.com/dockerzhang</uri>
        </author>
        <category label="Apache InLong" term="Apache InLong"/>
        <category label="Version" term="Version"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[1.4.0 版本发布]]></title>
        <id>https://inlong.apache.org/zh-CN/blog/2022/11/16/release-1.4.0</id>
        <link href="https://inlong.apache.org/zh-CN/blog/2022/11/16/release-1.4.0"/>
        <updated>2022-11-16T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Apache InLong（应龙）是一个一站式海量数据集成框架，提供自动、安全、可靠和高性能的数据传输能力，方便业务构建基于流式的数据分析、建模和应用。 InLong 支持大数据领域的采集、汇聚、缓存和分拣功能，用户只需要简单的配置就可以把数据从数据源导入到实时计算引擎或者落地到离线存储。]]></summary>
        <content type="html"><![CDATA[<p>Apache InLong（应龙）是一个一站式海量数据集成框架，提供自动、安全、可靠和高性能的数据传输能力，方便业务构建基于流式的数据分析、建模和应用。 InLong 支持大数据领域的采集、汇聚、缓存和分拣功能，用户只需要简单的配置就可以把数据从数据源导入到实时计算引擎或者落地到离线存储。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="140-版本总览">1.4.0 版本总览<a href="#140-版本总览" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>Apache InLong 最近发布了 1.4.0 版本，该版本关闭了约 364+ 个issue，包含 16+ 个特性和 120+ 个优化。主要完成了整库实时同步至 Apache Doris、整库实时同步至 Apache Iceberg、标准架构支持 HTTP 上报、标准架构新增 MongoDB 等多种采集节点。该版本还完成了大量其它特性，主要包括：</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-模块">Agent 模块<a href="#agent-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>重构了 Sink 发送指标</li><li>审计上报增加数据大小</li><li>支持 Redis、MQTT、SQLServer、Oracle 、MongoDB 数据源</li><li>强化 Kubernetes 环境文件采集能力</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dataproxy-模块">DataProxy 模块<a href="#dataproxy-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>心跳上报增加服务状态、支持认证</li><li>增加 proxy-send 模式发送数据</li><li>优化数据链路埋点指标</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="tubemq-模块">TubeMQ 模块<a href="#tubemq-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>增加客户端负载均衡消费组控制 API</li><li>C++ SDK 修复多个 Bug</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-模块">Manager 模块<a href="#manager-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>数据流 Group 和 Stream 支持扩展参数</li><li>Client 支持通过 Key 更新和删除数据流向</li><li>重构获取 Sort 集群配置信息方式</li><li>优化状态管理</li><li>Client 支持集群增删改查</li><li>集群节点上报新增协议类型</li><li>缓存层使用支持使用 Kafka</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-模块">Sort 模块<a href="#sort-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持 debezium-json 格式</li><li>Kafka 数据节点支持 Topic 动态感知</li><li>Hive/Hbase/Iceberg 等 connector 支持指标状态恢复</li><li>Elasticsearch 6/7、JDBC connector 增加指标状态</li><li>Iceberg sink 支持 schema revolution，能够自动建表并感知字段的增加</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dashboard-模块">Dashboard 模块<a href="#dashboard-模块" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>统一数据源、数据流向类型定义</li><li>集群管理新增 Agent 类型</li><li>增加数据节点管理</li><li>支持选择 Kafka 消息类型</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="其它">其它<a href="#其它" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>docker-compose 部署内置 Flink 环境</li><li>修复多个 aarch64 镜像 Bug</li><li>修复多个依赖安全漏洞</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="140-版本特性介绍">1.4.0 版本特性介绍<a href="#140-版本特性介绍" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-新增多种数据源">Agent 新增多种数据源<a href="#agent-新增多种数据源" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 1.4.0 版本中，Agent 支持了 Redis、MQTT、SQLServer、Oracle 、MongoDB 等数据源，使得标准架构和轻量化架构的采集能力基本对齐，用户在海量场景下也有了更多选择。这部分后端能力的支持主要由@iamsee123、@haibo-duan完成，前端部分由@bluewang完成。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="完善组件指标">完善组件指标<a href="#完善组件指标" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 1.4.0 版本中，Agent、DataProxy、Sort 模块都有指标的优化和完善，包括 Agent 发送指标的重构，增加数据Group/Stream指标维度，修复 Prometheus Listener 指标不准确等多个问题。感谢@Keylchen、@pocozh等贡献。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="优化-docker-compose-部署">优化 Docker-compose 部署<a href="#优化-docker-compose-部署" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>InLong 服务组件比较多，一直都有部署门槛高的问题。在 1.4.0 版本中，优化了 docker-compose 部署的兼容性，同时内置一个 Apache Flink 环境，帮助开发者快速开始创建任务。感谢@dockerzhang 针对这部分内容的优化。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="优化心跳管理">优化心跳管理<a href="#优化心跳管理" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 1.4.0 版本中，针对服务组件的心跳继续做了大量优化，包括上报时新增数据数据协议、Agent/DataProxy 组件上报自动注册、Manager 增加心跳管理 API 、优化多个心跳状态 Bug 等。感谢@gosonzhang、@GanfengTan、@pocozh、@lucaspeng12138和@haifxu的贡献。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持整库实时同步能力">支持整库实时同步能力<a href="#支持整库实时同步能力" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 1.4.0 版本中，InLong 开始支持整库实时同步，跟进社区用户的需求，目前率先实现了整库实时同步至Doris、整库实时同步至Iceberg，近期社区也会将整库同步实现的具体细节分享出来。感谢@thesumery、@EMsnap、@yunqingmoswu的贡献。</p><p>更多 1.4.0 版本的细节请参考 版本说明 ，其中详细列出了此版本的特性、提升和 Bug 修复。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="后续规划">后续规划<a href="#后续规划" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在下个版本中，社区会继续增加整库同步场景、完善任务指标以及增加系统稳定性，进行标准架构和轻量化架构的压测。</p>]]></content>
        <author>
            <name>Charles Zhang</name>
            <uri>https://github.com/dockerzhang</uri>
        </author>
        <category label="Apache InLong" term="Apache InLong"/>
        <category label="Version" term="Version"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[1.3.0 版本发布]]></title>
        <id>https://inlong.apache.org/zh-CN/blog/2022/09/05/release-1.3.0</id>
        <link href="https://inlong.apache.org/zh-CN/blog/2022/09/05/release-1.3.0"/>
        <updated>2022-09-05T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Apache InLong（应龙）是一个一站式海量数据集成框架，提供自动、安全、可靠和高性能的数据传输能力，同时支持批和流，方便业务构建基于流式的数据分析、建模和应用。]]></summary>
        <content type="html"><![CDATA[<p>Apache InLong（应龙）是一个一站式海量数据集成框架，提供自动、安全、可靠和高性能的数据传输能力，同时支持批和流，方便业务构建基于流式的数据分析、建模和应用。
InLong 支持大数据领域的采集、汇聚、缓存和分拣功能，用户只需要简单的配置就可以把数据从数据源导入到实时计算引擎或者落地到离线存储。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="130-版本特性总览">1.3.0 版本特性总览<a href="#130-版本特性总览" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p><strong>刚刚发布的 1.3.0 版本关闭了约 410+ 个 issue，包含 110+ 个特性和 170+ 个优化。</strong> 主要包括以下内容：</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="增强管控能力">增强管控能力<a href="#增强管控能力" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>增加 Open API 的权限认证</li><li>支持 Agent 和 DataProxy 集群的心跳上报机制</li><li>Manager 支持对“用户”和“审批人”等角色的管理</li><li>抽象 Load 节点的操作，以支持快速扩展 Load 节点的资源</li><li>支持创建 SQLServer、Oracle 和 MySQL 的数据库和表</li><li>增强 Manager 客户端的功能，包括但不限于用户和数据节点管理</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="扩展采集节点">扩展采集节点<a href="#扩展采集节点" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持采集 TubeMQ 中的数据</li><li>支持采集 Redis 中的数据</li><li>支持采集 Doris 中的数据</li><li>支持采集无 AdminUrl 的 Pulsar 中的数据</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="优化写入节点">优化写入节点<a href="#优化写入节点" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>Kafka Sink 支持 All Changelog Mode</li><li>JDBC Sink 支持 All Changelog Mode</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持数据转换">支持数据转换<a href="#支持数据转换" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持 Union 操作符</li><li>支持 加密 UDF</li><li>支持 JSON UDF</li><li>支持 Temporal Join/Lookup Join 连接</li><li>支持 Interval Join 连接</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="强化agent功能">强化Agent功能<a href="#强化agent功能" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持正则表达式自定义换行：默认 “\n” 行结束标识，自定义正则匹配行结束标识可以实现多行合并折叠</li><li>支持 K8s 日志采集并携带集群信息</li><li>支持标准输出、节点日志采集，针对标准输出会携带容器和集群信息</li><li>支持文件内容全量和增量采集</li><li>支持自动上报心跳和注册到 Manager</li><li>支持自定义 IP 和自动获取 IP</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="其他优化">其他优化<a href="#其他优化" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>GitHub Action 检查、流水线优化</li><li>DataProxy 完善审计、指标上报等监控能力</li><li>DataProxy 新增 C++ SDK 数据上报能力</li><li>Sort 支持指标上报以及 Audit 上报</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="130-版本特性介绍">1.3.0 版本特性介绍<a href="#130-版本特性介绍" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="抽象化-load-节点操作">抽象化 Load 节点操作<a href="#抽象化-load-节点操作" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>Manager 对 Load 节点的抽象操作，以支持快速扩展 Load 节点的资源，大幅减少 Load 节点的开发时间。
该部分功能由 @ciscozhou 贡献。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="增加-manager-open-api-的权限认证">增加 Manager Open API 的权限认证<a href="#增加-manager-open-api-的权限认证" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>旧版本中 Manager Open API 可以匿名访问，新版本中使用 Apache Shiro 框架实现了基于 Basic Access Authentication 的登录认证方式，该部分功能由 @woofyzhao 贡献。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="增强对文件数据和-k8s-日志的采集">增强对文件数据和 K8s 日志的采集<a href="#增强对文件数据和-k8s-日志的采集" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>1.3.0 版本增强了对文件数据以及 K8s 数据的采集，其中文件采集支持了正则表达式自定义换行符，从而可以实现多行合并折叠。
另外新版本 Agent 支持文件内容全量和增量采集，这些功能均由 @ganfengtan 贡献。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dataproxy-新增-c-sdk-能力">DataProxy 新增 C++ SDK 能力<a href="#dataproxy-新增-c-sdk-能力" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>DataProxy 在原 Java 客户端之外，新增了 C++ 的客户端能力，该部分功能由 @pocozh 贡献。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-支持多种-udf-以及-join-操作符">Sort 支持多种 UDF 以及 join 操作符<a href="#sort-支持多种-udf-以及-join-操作符" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>Sort 支持 Temporal Join / Lookup Join / Interval Join，该部分功能由 @yunqingmoswu 贡献。</p><p>另外，大量社区用户提出需要加解密和 JSON UDF 的功能，在此版本中，@Emsnap 和 @Emhui 贡献了相关特性。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-connector-支持指标上报功能">Sort Connector 支持指标上报功能<a href="#sort-connector-支持指标上报功能" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>新版本的 Sort Connector 中支持多种 Connector 的 Flink 内置指标上报，外部指标系统能够比如 Prometheus 能够直接获任务数据读取以及写入的条数和速率。</p><p>除此之外，新版本还支持 InLong Audit 审计数据上报，该部分功能由 @pacigong、@Emsnap、@thesumery，@Oneal65 和 @yunqingmoswu 等人贡献。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-支持创建多种流向的资源">Manager 支持创建多种流向的资源<a href="#manager-支持创建多种流向的资源" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>1.3.0 版本中 Manager 增加了对部分存储资源（库表结构）的创建：</p><ul><li>创建 SQLServer 的 库和表</li><li>创建 Oracle 的库和表</li><li>创建 MySQL 的库和表</li></ul><p>以上特性均由社区爱好者 @haibo-duan 贡献。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="其他特性及问题修复">其他特性及问题修复<a href="#其他特性及问题修复" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>更多内容，请参考 <a href="https://github.com/apache/inlong/blob/master/CHANGES.md" target="_blank" rel="noopener noreferrer">版本说明</a> ，其中详细列出了此版本的特性、提升和 Bug 修复。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="apache-inlong-后续规划">Apache InLong 后续规划<a href="#apache-inlong-后续规划" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>后续版本，我们扩展更多的数据源端和存储端，覆盖更多的使用场景，并逐步提升系统的易用性和健壮性，主要包括：</p><ul><li>Agent 新增 Redis、CloudEvents、MongoDB 采集类型</li><li>统一 DataProxy 中 MQ 的处理方式</li><li>全链路支持 Apache Kafka</li></ul>]]></content>
        <author>
            <name>EMsnap</name>
            <uri>https://github.com/EMsnap</uri>
        </author>
        <category label="Apache InLong" term="Apache InLong"/>
        <category label="Version" term="Version"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[1.2.0 版本发布]]></title>
        <id>https://inlong.apache.org/zh-CN/blog/2022/06/22/release-1.2.0</id>
        <link href="https://inlong.apache.org/zh-CN/blog/2022/06/22/release-1.2.0"/>
        <updated>2022-06-22T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Apache InLong（应龙）是一个一站式海量数据集成框架，提供自动、安全、可靠和高性能的数据传输能力，同时支持批和流，方便业务构建基于流式的数据分析、建模和应用。]]></summary>
        <content type="html"><![CDATA[<p>Apache InLong（应龙）是一个一站式海量数据集成框架，提供自动、安全、可靠和高性能的数据传输能力，同时支持批和流，方便业务构建基于流式的数据分析、建模和应用。
InLong 支持大数据领域的采集、汇聚、缓存和分拣功能，用户只需要简单的配置就可以把数据从数据源导入到实时计算引擎或者落地到离线存储。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="120-版本特性总览">1.2.0 版本特性总览<a href="#120-版本特性总览" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p><strong>刚刚发布的 1.2.0-incubating 版本关闭了约 410+ 个 issue，包含 30+ 个特性和 190+ 个优化。</strong>
主要包括以下内容：</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="增强管控能力">增强管控能力<a href="#增强管控能力" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>Dashboard 和 Manager 增加集群管理能力</li><li>Dashboard 优化数据流的创建流程</li><li>Manager 支持 MQ 的插件化扩展</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="扩展采集节点">扩展采集节点<a href="#扩展采集节点" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持采集 Pulsar 中的数据</li><li>支持采集 MongoDB-CDC 中的数据</li><li>支持采集 MySQL-CDC 中的数据</li><li>支持采集 Oracle-CDC 中的数据</li><li>支持采集 PostgreSQL-CDC 中的数据</li><li>支持采集 SQLServer-CDC 中的数据</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="扩展写入节点">扩展写入节点<a href="#扩展写入节点" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持将数据写入 Kafka</li><li>支持将数据写入 HBase</li><li>支持将数据写入 PostgreSQL</li><li>支持将数据写入 Oracle</li><li>支持将数据写入 MySQL</li><li>支持将数据写入 TDSQL-PostgreSQL</li><li>支持将数据写入 Greenplum</li><li>支持将数据写入 SQLServer</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持数据转换">支持数据转换<a href="#支持数据转换" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持字符串切割</li><li>支持字符串正则替换</li><li>支持字符串正则替换第一个匹配的值</li><li>支持数据过滤</li><li>支持数据去重</li><li>支持 Regular Join</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="增强系统监控功能">增强系统监控功能<a href="#增强系统监控功能" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持数据链路心跳的上报和管理</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="其他优化">其他优化<a href="#其他优化" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持 DataProxy 多集群配置的下发</li><li>GitHub Action 检查、流水线优化</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="120-版本特性介绍">1.2.0 版本特性介绍<a href="#120-版本特性介绍" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持多集群管理">支持多集群管理<a href="#支持多集群管理" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>Manager 增加了集群管理功能，支持多集群配置，解决了只能通过配置文件定义一套集群的限制，用户可根据需要在 Dashboard 创建不同类型的集群。</p><p>多集群功能主要由 @healchow、@luchunliang、@leezng 设计和实现，感谢三位贡献者。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="增强对文件数据和-mysql-binlog-的采集">增强对文件数据和 MySQL Binlog 的采集<a href="#增强对文件数据和-mysql-binlog-的采集" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>1.2.0 版本支持采集完整的文件数据，同时也支持从 MySQL 的指定 Binlog 位置开始采集数据。该部分工作由 @Greedyu 完成。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持整库迁移">支持整库迁移<a href="#支持整库迁移" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>Sort 支持对整个数据库中的数据进行迁移，此特性由 @EMsnap 贡献。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持写入-canal-格式的数据">支持写入 Canal 格式的数据<a href="#支持写入-canal-格式的数据" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>支持向 Kafka 写入 Canal 格式的数据，此特性由 @thexiay 贡献。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="优化-manager-client-中的-http-请求方式">优化 Manager Client 中的 HTTP 请求方式<a href="#优化-manager-client-中的-http-请求方式" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>优化了 Manager Client 中执行 HTTP 请求的方式，并为 Client 增加单元测试，在减少重复代码的同时，降低维护成本。
此特性由新加入的贡献者 @leosanqing 贡献。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持运行-sql-脚本">支持运行 SQL 脚本<a href="#支持运行-sql-脚本" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>Sort 支持运行 SQL 脚本，详见 <a href="https://github.com/apache/inlong/issues/4405" target="_blank" rel="noopener noreferrer">INLONG-4405</a> ，感谢 @gong 贡献此特性。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持数据链路心跳的上报和管理">支持数据链路心跳的上报和管理<a href="#支持数据链路心跳的上报和管理" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>此版本支持数据分组、数据流及底层组件的心跳上报和管理，是后续系统各环节的状态管理的前提。此特性主要由 @baomingyu、@healchow 和 @kipshi 设计和贡献。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-支持创建多种流向的资源">Manager 支持创建多种流向的资源<a href="#manager-支持创建多种流向的资源" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>1.2.0 版本中 Manager 增加了对部分存储资源的创建：</p><ul><li>创建 Kafka 的 Topic（@woofyzhao 贡献）</li><li>创建 Iceberg 的库和表（@woofyzhao 贡献）</li><li>创建 HBase 的命名空间和表（@woofyzhao 贡献）</li><li>创建 ClickHouse 的库和表（@lucaspeng12138 贡献）</li><li>创建 Elasticsearch 的索引（@lucaspeng12138 贡献）</li><li>创建 PostgreSQL 的库和表（@baomingyu 贡献）</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-支持轻量化架构">Sort 支持轻量化架构<a href="#sort-支持轻量化架构" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>1.2.0 版本的 Sort 做了大量重构和提升，通过引入 Flink-CDC，支持多种 Extract 和 Load 节点，同时也支持数据的转换（即 Transform）。</p><p>此特性包含非常多的子特性，主要的开发者有：@baomingyu，@EMsnap，@GanfengTan，@gong，@lucaspeng12138，@LvJiancheng，@kipshi，@thexiay，@woofyzhao，@yunqingmoswu，感谢各位的贡献。</p><p>更多特性信息，请参考：<a href="/zh-CN/blog/2022/06/16/inlong-sort-etl">InLong Sort ETL 方案解析</a>。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="其他特性及问题修复">其他特性及问题修复<a href="#其他特性及问题修复" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>相关内容请参考 <a href="https://github.com/apache/inlong/blob/master/CHANGES.md" target="_blank" rel="noopener noreferrer">版本说明</a> ，其中详细列出了此版本的特性、提升和 Bug 修复。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="apache-inlong-后续规划">Apache InLong 后续规划<a href="#apache-inlong-后续规划" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>后续版本，我们扩展更多的数据源端和存储端，覆盖更多的使用场景，并逐步提升系统的易用性和健壮性，主要包括：</p><ul><li>各组件的心跳上报</li><li>数据链路的状态管理</li><li>全链路审计支持写入 ClickHouse</li><li>扩展更多类型的采集节点和存储节点</li></ul>]]></content>
        <author>
            <name>healchow</name>
            <uri>https://github.com/healchow</uri>
        </author>
        <category label="Apache InLong" term="Apache InLong"/>
        <category label="Version" term="Version"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[InLong Sort ETL 方案解析]]></title>
        <id>https://inlong.apache.org/zh-CN/blog/2022/06/16/inlong-sort-etl</id>
        <link href="https://inlong.apache.org/zh-CN/blog/2022/06/16/inlong-sort-etl"/>
        <updated>2022-06-16T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[1. 背景]]></summary>
        <content type="html"><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-背景">1. 背景<a href="#1-背景" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>随着 Apache InLong(incubating) 的用户和开发者逐渐增多，更丰富的使用场景和低成本运营诉求越来越强烈，其中，InLong 全链路增加 Transform（T）的需求反馈最多。经过@yunqingmoswu、@EMsnap、@gong、@thexiay 社区开发者的调研和设计，完成了基于 Flink SQL 的 InLong Sort ETL 方案，本文将详细介绍该方案的实现细节。</p><p>首先，基于 Apache Flink SQL 主要有以下方面的考量：</p><ul><li>Flink SQL 拥有强大的表达能力带来的高可扩展性、灵活性，基本上 Flink SQL 能支持社区大多数需求场景。当 Flink SQL 内置的函数不满足需求时，我们还可通过各种UDF来扩展。</li><li>Flink SQL 相比 Flink 底层 API 实现开发成本更低，只有第一次需要实现 Flink SQL 的转换逻辑，后续可专注于 Flink SQL 能力本身的构建，比如扩展 Connector、自定义函数UDF等。</li><li>一般来说，Flink SQL 将更健壮、运行也将更稳定。原因在于 Flink SQL 屏蔽了 Flink 底层大量的细节，有强大的社区支持，并且经过大量用户的实践。</li><li>对用户来说，Flink SQL 也更加通俗易懂，特别是对使用过 SQL 用户来说，使用方式简单、熟悉，这有助于用户快速落地。</li><li>对于存量实时任务的迁移，如果其原本就是 SQL 类型的任务，尤其是 Flink SQL 任务，其迁移成本极低，部分情况下甚至都不用做任何改动。</li></ul><p>注意：本方案的所有代码，可以参考 <a href="https://github.com/apache/incubator-inlong/tree/master/inlong-sort" target="_blank" rel="noopener noreferrer">Apache InLong Sort</a> 模块，所含功能可在即将发布的 1.2.0 版本中下载使用。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-方案介绍">2. 方案介绍<a href="#2-方案介绍" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="21-方案需求">2.1 方案需求<a href="#21-方案需求" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>该方案的主要需求，是完成的 InLong Sort 模块 Transform（T）能力，包括：</p><table><thead><tr><th align="center">Transform</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center">窗口内去重</td><td align="center">在一个时间窗口内对数据去重</td></tr><tr><td align="center">时间窗口聚合</td><td align="center">在一个时间窗口内对数据进行聚合操作</td></tr><tr><td align="center">时间格式转换</td><td align="center">将一个字段的值转换为目标时间格式的字符串</td></tr><tr><td align="center">字段分割</td><td align="center">将一个字段通过某个分割符分割为多个新的字段</td></tr><tr><td align="center">字符串替换</td><td align="center">将替换一个字符串字段中的部分或全部内容</td></tr><tr><td align="center">数据过滤</td><td align="center">将满足过滤条件的数据舍弃或者保留</td></tr><tr><td align="center">内容提取</td><td align="center">提取一个字段的一部分产生一个新的字段</td></tr><tr><td align="center">连接</td><td align="center">支持两表 Join</td></tr><tr><td align="center">值替换</td><td align="center">给定一个匹配值，如果该字段的值等于该值，则将其替换为目标值</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_LWe7" id="22-使用场景">2.2 使用场景<a href="#22-使用场景" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>大数据集成的用户，在很多业务场景下都有数据转换、连接、过滤等 Transform 需求。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="23-设计目标">2.3 设计目标<a href="#23-设计目标" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>本次设计需要达到以下目标：</p><ul><li>功能性：在 InLong Sort 现有架构、数据流模型下，覆盖基本的 Transform 能力，并具备快速扩张的能力。</li><li>兼容性：新的 InLong Sort 数据模型向前兼容，确保历史任务能够正常配置运行。</li><li>可维护性：InLong Sort 数据模型转 Flink SQL 只需实现一遍，后期有新增的功能需求时，这块不需要改动，哪怕有改动也是少量改动即可支持。</li><li>可扩展性：当出现开源 Flink Connector 或者内置 Flink SQL 函数不满足需求时，可通过自定义 Flink Connector、UDF 来实现其功能扩展。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="24-基本概念">2.4 基本概念<a href="#24-基本概念" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>核心概念参照概要设计中的名词解释</p><table><thead><tr><th align="center">名称</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center">InLong Dashborad</td><td align="center">Inlong 前端管理界面</td></tr><tr><td align="center">InLong Manager Client</td><td align="center">将 Manager 当中的接口进行包装，供外部用户程序调用，不经过前端 InLong Dashboard</td></tr><tr><td align="center">InLong Manager Openapi</td><td align="center">Inlong manager 与外部系统调用接口</td></tr><tr><td align="center">InLong Manager metaData</td><td align="center">Inlong manager 元数据管理，包括 group、stream 纬度的元数据信息</td></tr><tr><td align="center">InLong Manager task manager</td><td align="center">Inlong manager中管理数据源采集任务模块，管理agent的任务下发，指令下发，心跳上报</td></tr><tr><td align="center">InLong Group</td><td align="center">数据流组，包含多个数据流，一个 Group 代表一个数据接入</td></tr><tr><td align="center">InLong Stream</td><td align="center">数据流，一个数据流有具体的流向</td></tr><tr><td align="center">Stream Source</td><td align="center">流中有对应的采集端和 sink 端，本设计中只涉及到 stream source</td></tr><tr><td align="center">Stream Info</td><td align="center">Sort 中数据流向的抽象，包含该数据流的各种来源、转换、去向等</td></tr><tr><td align="center">Group Info</td><td align="center">Sort 中对数据流向的封装，一个 GroupInfo 可包含多个 Stream Info</td></tr><tr><td align="center">Node</td><td align="center">数据同步中数据源、数据转换、数据去向的抽象</td></tr><tr><td align="center">Extract Node</td><td align="center">数据同步的来源端抽象</td></tr><tr><td align="center">Load Node</td><td align="center">数据同步的去向端抽象</td></tr><tr><td align="center">MySQL Extract Node</td><td align="center">MySQL 数据来源抽象</td></tr><tr><td align="center">Kafka Load Node</td><td align="center">Kafka 数据去向抽象</td></tr><tr><td align="center">Transform Node</td><td align="center">数据同步的转换过程抽象</td></tr><tr><td align="center">Aggregate Transform Node</td><td align="center">数据同步聚合类转换过程抽象</td></tr><tr><td align="center">Node Relation</td><td align="center">数据同步中各个节点关系抽象</td></tr><tr><td align="center">Field Relation</td><td align="center">数据同步中上下游节点字段间关系的抽象</td></tr><tr><td align="center">Function</td><td align="center">转换函数的抽象，即数据同步T中各个 T 能力实现的抽象</td></tr><tr><td align="center">Substring Function</td><td align="center">字符串截取函数的抽象</td></tr><tr><td align="center">Filter Function</td><td align="center">数据过滤函数的抽象</td></tr><tr><td align="center">Function Param</td><td align="center">函数的入参抽象</td></tr><tr><td align="center">Constant Param</td><td align="center">常量参数</td></tr><tr><td align="center">Field Info</td><td align="center">节点字段</td></tr><tr><td align="center">Meta FieldInfo</td><td align="center">节点元信息字段</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_LWe7" id="25-领域模型">2.5 领域模型<a href="#25-领域模型" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>本次设计主要涉及到以下实体：</p><p>Group、Stream、GroupInfo、StreamInfo、Node、NodeRelation、FieldRelation、Function、FilterFunction、SubstringFunction、FunctionParam、FieldInfo、MetaFieldInfo、MySQLExtractNode、KafkaLoadNode 等</p><p>为了便于理解，本小节将对实体之间关系进行建模分析。领域模型的实体对应关系说明：</p><ul><li>一个 Group 对应 1 个 GroupInfo</li><li>一个 Stream 对应 1 个 StreamInfo</li><li>一个 Group 包含 1 个或多个 Stream</li><li>一个 GroupInfo 包含 1 个或多个 StreamInfo</li><li>一个 StreamInfo 包含多个 Node</li><li>一个 StreamInfo 包含 1 个或多个 NodeRelation</li><li>一个 NodeRelation 包含 1 个或多个 FieldRelation</li><li>一个 NodeRelation 包含 0 个或多个 FilterFunction</li><li>一个 FieldRelation 包含 1 个 Function 或 1 个 FieldInfo 作为来源字段，1 个 FieldInfo 作为目标字段</li><li>一个 Function 包含 1 个或多个 FunctionParam</li></ul><p>上述关系由 UML 对象关系图可以表示为：</p><p><img loading="lazy" alt="sort_UML" src="/zh-CN/assets/images/sort_UML-896d751427509d769add998680df9516.png" width="2576" height="869" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="26-功能用例图">2.6 功能用例图<a href="#26-功能用例图" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p><img loading="lazy" alt="sort-usecase" src="/zh-CN/assets/images/sort-usecase-fb8639f9724899ab3afcbf35b8a21902.png" width="606" height="356" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-系统概要设计">3. 系统概要设计<a href="#3-系统概要设计" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="31-系统架构图">3.1 系统架构图<a href="#31-系统架构图" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p><img loading="lazy" alt="architecture" src="/zh-CN/assets/images/architecture-b4c0fb3783a6ed2f2868f534df98e74b.png" width="461" height="741" class="img_ev3q"></p><ul><li>Serialization：序列化实现模块</li><li>Deserialization：反序列化实现模块</li><li>Flink Source：自定义 Flink source实现模块</li><li>Flink Sink：自定义的 Flink sink 实现模块</li><li>Transformation：自定义的 Transform 实现模块</li><li>GroupInfo：对应 Inlong group</li><li>StreamInfo：对应 Inlong stream</li><li>Node：对数据同步中数据来源、数据转换、数据去向的抽象</li><li>FlinkSQLParser：SQL 解析器</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="32-inlong-sort-内部运行流程图">3.2 InLong Sort 内部运行流程图<a href="#32-inlong-sort-内部运行流程图" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p><img loading="lazy" src="/zh-CN/assets/images/sort-operation-flow-77363f12a68a011beba26db9ccc6fedb.png" width="771" height="61" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="33-模块设计">3.3 模块设计<a href="#33-模块设计" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>本次设计只对原有系统增加 Flink Connector、FlinkSQL Generator 两个模块，对 Data Model 模块有修改。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="331-模块结构">3.3.1 模块结构<a href="#331-模块结构" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4><p><img loading="lazy" src="/zh-CN/assets/images/sort-module-structure-4dd424ae93043cb912dba69c08590b33.png" width="771" height="1011" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="332-模块划分">3.3.2 模块划分<a href="#332-模块划分" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4><p>重要模块划分说明：</p><table><thead><tr><th align="center">名称</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center">FlinkSQLParser</td><td align="center">用于生成 FlinkSQL 核心类，包含 GroupInfo 的引用</td></tr><tr><td align="center">GroupInfo</td><td align="center">Sort 内部对 InlongGroup 的抽象，用于封装整个 InlongGroup 同步相关信息，包含对 List\&lt;StreamInfo<!-- -->&gt;<!-- --> 的引用</td></tr><tr><td align="center">StreamInfo</td><td align="center">Sort 内部对 InlongStream 的抽象，用于封装 InlongStream 同步相关信息，包含List\&lt;Node<!-- -->&gt;<!-- -->、List\&lt;NodeRelation<!-- -->&gt;<!-- --> 的引用</td></tr><tr><td align="center">Node</td><td align="center">同步节点的顶层接口，它的各个子类实现主要用于对同步数据源、转换节点的数据封装</td></tr><tr><td align="center">ExtractNode</td><td align="center">数据extract节点抽象，继承自 Node</td></tr><tr><td align="center">LoadNode</td><td align="center">数据load节点抽象，继承自 Node</td></tr><tr><td align="center">TransformNode</td><td align="center">数据转换节点抽象，继承自 Node</td></tr><tr><td align="center">NodeRelation</td><td align="center">定义节点间的关系</td></tr><tr><td align="center">FieldRelation</td><td align="center">定义节点间字段的关系</td></tr><tr><td align="center">Function</td><td align="center">T能力执行函数的抽象</td></tr><tr><td align="center">FilterFunction</td><td align="center">用于数据过滤的 Function 抽象，继承自 Function</td></tr><tr><td align="center">SubstringFunction</td><td align="center">用于字符串截取 Function 抽象，继承自 Function</td></tr><tr><td align="center">FunctionParam</td><td align="center">用于函数参数的抽象</td></tr><tr><td align="center">ConstantParam</td><td align="center">函数常量参数的封装，继承自 FunctionParam</td></tr><tr><td align="center">FieldInfo</td><td align="center">节点字段的封装，也可做函数入参使用，继承自 FunctionParam</td></tr><tr><td align="center">MetaFieldInfo</td><td align="center">内置字段的封装，目前主要用于 canal-json 的元数据字段场景，继承自 FieldInfo</td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-系统详细设计">4. 系统详细设计<a href="#4-系统详细设计" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>下面以同步 MySQL 中的数据到 Kafka 为例来说明 SQL 的生成原理。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="41-node-生成-sql">4.1 Node 生成 SQL<a href="#41-node-生成-sql" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="411-extractnode-生成-sql">4.1.1 ExtractNode 生成 SQL<a href="#411-extractnode-生成-sql" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4><p>节点配置为：</p><div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"> private Node buildMySQLExtractNode() {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        List&lt;FieldInfo&gt; fields = Arrays.asList(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                new FieldInfo("name", new StringFormatInfo()),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                new FieldInfo("age", new IntFormatInfo()));</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return new MySqlExtractNode("1", "mysql_input", fields,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                null, null, "id",</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                Collections.singletonList("tableName"), "localhost", "root", "password",</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                "inlong", null, null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                null, null);</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>生成的 SQL 为：</p><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">mysql_1</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> string</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">age</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">with</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">'connector'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'mysql-cdc-inlong'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'hostname'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'localhost'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'username'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'root'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'password'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'password'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'database-name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'inlong'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'table-name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'tableName'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="412-transformnode-生成-sql">4.1.2 TransformNode 生成 SQL<a href="#412-transformnode-生成-sql" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4><p>节点配置为：</p><div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"> List&lt;FilterFunction&gt; filters = Arrays.asList(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                new SingleValueFilterFunction(EmptyOperator.getInstance(),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        new FieldInfo("age", new IntFormatInfo()),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        LessThanOperator.getInstance(), new ConstantParam(25)),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                new SingleValueFilterFunction(AndOperator.getInstance(),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        new FieldInfo("age", new IntFormatInfo()),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        MoreThanOrEqualOperator.getInstance(), new ConstantParam(18))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        );</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>生成的 SQL 为：</p><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SELECT</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">age</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">age</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">FROM</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">mysql_1</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WHERE</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">age</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token operator">&lt;</span><span class="token plain"> </span><span class="token number">25</span><span class="token plain"> </span><span class="token operator">AND</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">age</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token operator">&gt;=</span><span class="token plain"> </span><span class="token number">18</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="413-loadnode-生成-sql">4.1.3 LoadNode 生成 SQL<a href="#413-loadnode-生成-sql" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4><p>节点配置为：</p><div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"> private Node buildKafkaLoadNode(FilterStrategy filterStrategy) {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        List&lt;FieldInfo&gt; fields = Arrays.asList(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                new FieldInfo("name", new StringFormatInfo()),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                new FieldInfo("age", new IntFormatInfo())</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        List&lt;FieldRelation&gt; relations = Arrays</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                .asList(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        new FieldRelation(new FieldInfo("name", new StringFormatInfo()),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                                new FieldInfo("name", new StringFormatInfo())),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        new FieldRelation(new FieldInfo("age", new IntFormatInfo()),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                                new FieldInfo("age", new IntFormatInfo()))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                );</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        List&lt;FilterFunction&gt; filters = Arrays.asList(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                new SingleValueFilterFunction(EmptyOperator.getInstance(),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        new FieldInfo("age", new IntFormatInfo()),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        LessThanOperator.getInstance(), new ConstantParam(25)),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                new SingleValueFilterFunction(AndOperator.getInstance(),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        new FieldInfo("age", new IntFormatInfo()),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        MoreThanOrEqualOperator.getInstance(), new ConstantParam(18))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return new KafkaLoadNode("2", "kafka_output", fields, relations, filters,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                filterStrategy, "topic1", "localhost:9092",</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                new CanalJsonFormat(), null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                null, "id");</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>生成的 SQL 为：</p><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">kafka_3</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> string</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">age</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">with</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'kafka-inlong'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'topic'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'topic1'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'properties.bootstrap.servers'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'localhost:9092'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'format'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'canal-json-inlong'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'canal-json-inlong.ignore-parse-errors'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'true'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'canal-json-inlong.map-null-key.mode'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'DROP'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'canal-json-inlong.encode.decimal-as-plain-number'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'true'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'canal-json-inlong.timestamp-format.standard'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'SQL'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'canal-json-inlong.map-null-key.literal'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'null'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="42-字段-t-生成-sql">4.2 字段 T 生成 SQL<a href="#42-字段-t-生成-sql" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="421-过滤算子">4.2.1 过滤算子<a href="#421-过滤算子" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4><p>相关配置见 4.1 节点配置</p><p>生成的 SQL 为：</p><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INSERT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INTO</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">kafka_3</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SELECT</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">age</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">age</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">FROM</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">mysql_1</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WHERE</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">age</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token operator">&lt;</span><span class="token plain"> </span><span class="token number">25</span><span class="token plain"> </span><span class="token operator">AND</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">age</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token operator">&gt;=</span><span class="token plain"> </span><span class="token number">18</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="422-水位线">4.2.2 水位线<a href="#422-水位线" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4><p>GroupInfo 完整配置如下：</p><div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">private Node buildMySqlExtractNode() {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        List&lt;FieldInfo&gt; fields = Arrays.asList(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                new FieldInfo("name", new StringFormatInfo()),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                new FieldInfo("age", new IntFormatInfo()),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                new FieldInfo("ts", new TimestampFormatInfo()));</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        WatermarkField wk = new WatermarkField(new FieldInfo("ts", new TimestampFormatInfo()),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                new StringConstantParam("1"),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                new TimeUnitConstantParam(TimeUnit.MINUTE));</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return new MySqlExtractNode("1", "mysql_input", fields,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                wk, null, "id",</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                Collections.singletonList("tableName"), "localhost", "root", "password",</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                "inlong", null, null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                null, null);</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    private Node buildKafkaNode() {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        List&lt;FieldInfo&gt; fields = Arrays.asList(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                new FieldInfo("name", new StringFormatInfo()),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                new FieldInfo("age", new IntFormatInfo()),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                new FieldInfo("ts", new TimestampFormatInfo()));</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        List&lt;FieldRelation&gt; relations = Arrays</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                .asList(new FieldRelation(new FieldInfo("name", new StringFormatInfo()),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                                new FieldInfo("name", new StringFormatInfo())),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        new FieldRelation(new FieldInfo("age", new IntFormatInfo()),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                                new FieldInfo("age", new IntFormatInfo()))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                );</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return new KafkaLoadNode("2", "kafka_output", fields, relations, null, null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                "topic", "localhost:9092", new JsonFormat(),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                1, null, "id");</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    private NodeRelation buildNodeRelation(List&lt;Node&gt; inputs, List&lt;Node&gt; outputs) {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        List&lt;String&gt; inputIds = inputs.stream().map(Node::getId).collect(Collectors.toList());</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        List&lt;String&gt; outputIds = outputs.stream().map(Node::getId).collect(Collectors.toList());</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return new NodeRelation(inputIds, outputIds);</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @Override</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    public GroupInfo getTestObject() {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        Node input = buildMySqlExtractNode();</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        Node output = buildKafkaNode();</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        StreamInfo streamInfo = new StreamInfo("1", Arrays.asList(input, output), Collections.singletonList(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                buildNodeRelation(Collections.singletonList(input), Collections.singletonList(output))));</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return new GroupInfo("1", Collections.singletonList(streamInfo));</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>]]></content>
        <author>
            <name>Oneal65</name>
            <uri>https://github.com/Oneal65</uri>
        </author>
        <category label="Apache InLong" term="Apache InLong"/>
        <category label="Sort" term="Sort"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[1.1.0 版本发布]]></title>
        <id>https://inlong.apache.org/zh-CN/blog/2022/04/25/release-1.1.0</id>
        <link href="https://inlong.apache.org/zh-CN/blog/2022/04/25/release-1.1.0"/>
        <updated>2022-04-25T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Apache InLong（应龙）是一个一站式海量数据集成框架，提供自动、安全、可靠和高性能的数据传输能力，同时支持批和流，方便业务构建基于流式的数据分析、建模和应用。InLong支持大数据领域的采集、汇聚、缓存和分拣功能，用户只需要简单的配置就可以把数据从数据源导入到实时计算引擎或者落地到离线存储。]]></summary>
        <content type="html"><![CDATA[<p>Apache InLong（应龙）是一个一站式海量数据集成框架，提供自动、安全、可靠和高性能的数据传输能力，同时支持批和流，方便业务构建基于流式的数据分析、建模和应用。InLong支持大数据领域的采集、汇聚、缓存和分拣功能，用户只需要简单的配置就可以把数据从数据源导入到实时计算引擎或者落地到离线存储。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="110-版本特性总览">1.1.0 版本特性总览<a href="#110-版本特性总览" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>刚刚发布的 1.1.0-incubating 主要包括以下内容：</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="管控能力增强">管控能力增强<a href="#管控能力增强" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>增加 Manager Client，支持集成 InLong 创建任务</li><li>增加 ManagerCtl 命令行工具，支持查看、创建数据流</li><li>Manager 支持下发 Agent 任务</li><li>Manager 支持下发 Sort Flink 任务</li><li>Manger 流向任务管理，支持启动、重启、暂停操作</li><li>Manager 插件化改造</li><li>Manager 元数据管理支持使用 MySQL</li><li>集群管理一期，统一集群信息注册</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="数据节点丰富">数据节点丰富<a href="#数据节点丰富" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>支持 Iceberg 流向入库</li><li>支持 ClickHouse 流向入库</li><li>支持 MySQL Binlog 采集</li><li>支持 Kafka 采集</li><li>Sort Standalone 支持多流向</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="配套工具建设">配套工具建设<a href="#配套工具建设" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>Dashboard 插件化改造</li><li>Kubernetes 部署优化</li><li>Standalone 部署重构</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="系统升级">系统升级<a href="#系统升级" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><ul><li>Protocol Buffers 升级</li><li>统一版本 Maven 版本依赖</li><li>修复一批依赖 CVEs 问题</li><li>DataProxy 支持 PB 压缩协议</li></ul><p>该版本关闭了约 642+ 个 issue，包含 23+ 个重大 feature 和 180+ 个 improvements。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="110-版本特性介绍">1.1.0 版本特性介绍<a href="#110-版本特性介绍" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="增加-manager-client">增加 Manager Client<a href="#增加-manager-client" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>新增的 Manager Client，定义了常见的 InLong Group/Stream 操作接口，包括任务的创建、查看和删除。用户通过 Manager Client，可以将 InLong 内置到任何第三方平台中，实现统一的定制化平台建设。Manager Client 主要是由 @kipshi 、 @gong、@ciscozhou 设计和实现，感谢三位贡献者。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="增加-managerctl-命令行工具">增加 ManagerCtl 命令行工具<a href="#增加-managerctl-命令行工具" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>ManagerCtl 基于 Manager Client 开发完成，是一个操作 InLong 资源的命令行工具，可以进一步简化开发者的使用。ManagerCtl 是由 @haifxu 独立贡献，包括指引包括：</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">Usage: managerctl [options] [command] [command options]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Options:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-h, --help</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Get all command about managerctl.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Commands:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">create      Create resource by json file</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Usage: create [options]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">​</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">describe      Display details of one or more resources</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Usage: describe [options]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">​</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">list      Displays main information for one or more resources</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Usage: list [options]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-支持下发-sort-任务">Manager 支持下发 Sort 任务<a href="#manager-支持下发-sort-任务" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在之前版本，用户创建完数据流 Group/Stream 任务后，Sort 需要通过命令行提交到 Flink 集群，再去执行数据分拣工作。在 1.1.0 版本中，我们将 Sort 任务的启动、停止、挂起操作，统一到 Manager 完成，用户只需要在 Manager 部署时配置正确的 Flink 集群，当数据流审批通过后，会自动拉起 Sort 任务。该部分工作主要是由 @LvJiancheng 贡献完成。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="manager-元数据保存去-zookeeper">Manager 元数据保存去 ZooKeeper<a href="#manager-元数据保存去-zookeeper" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>InLong 使用 ZooKeeper 保存数据流元数据，增加了开发者和用户的部署门槛和运维难度。在 1.1.0 版本中，我们默认将数据流元数据保存在 DB 中，ZooKeeper 只作为大规模场景下可选方案。感谢 @kipshi @yunqingmoswu 贡献了去 ZooKeeper 的 PR。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持-mysql-binlog-采集">支持 MySQL Binlog 采集<a href="#支持-mysql-binlog-采集" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>1.1.0 版本完整支持了从 MySQL 采集数据，支持增量和全量两种策略，用户可以在 InLong 简单配置就可以实现 MySQL 数据的采集。该部分工作是由 @EMsnap 贡献完成。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-新增-iceberg-clickhouse-kafka-流向入库">Sort 新增 Iceberg、 ClickHouse、 Kafka 流向入库<a href="#sort-新增-iceberg-clickhouse-kafka-流向入库" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>1.1.0 版本中增加了多种场景数据节点的入库，包括 Iceberg、 ClickHouse、 Kafka，这三种流向的支持丰富了 InLong 的使用场景。新流向的支持，主要由@chantccc @KevinWen007 @healchow 参与贡献。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="sort-standalone-支持-hiveelasticsearchkafka">Sort Standalone 支持 Hive、Elasticsearch、Kafka<a href="#sort-standalone-支持-hiveelasticsearchkafka" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>之前版本有提到，对于非 Flink 环境，我们可以通过 Sort Standalone 来进行数据流分拣。在 1.1.0 版本中，我们增加了对 Hive、ElasticSearch、Kafka 的支持，扩展了 Sort Standalone 的使用场景。Sort Standalone 主要有 @vernedeng @luchunliang 参与贡献。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="protocol-buffers-升级">Protocol Buffers 升级<a href="#protocol-buffers-升级" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>InLong 所有组件 Protocol Buffers 依赖从 2.5.0 升级到 3.19.4，感谢 @gosonzhang @doleyzi 的贡献，为 Protocol Buffers 升级做的大量兼容和测试工作。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="inlong-on-kubernetes-优化">InLong on Kubernetes 优化<a href="#inlong-on-kubernetes-优化" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>InLong on Kubernetes 的优化工作主要包括增加 Audit、梳理配置、优化消息队列使用、优化文档使用等，方便 InLong 上云的使用。感谢 @shink 为这些优化做的贡献。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dashboard-插件化">Dashboard 插件化<a href="#dashboard-插件化" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>为了方便用户快速在 Dashboard 构建新的流向，1.1.0 版本中实现了 Dashboard 插件化，了解 JavaScript 开发者基于插件开发指引，可以快速扩展新的数据流向。这部分工作感谢 @leezng</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="其他特性及问题修复">其他特性及问题修复<a href="#其他特性及问题修复" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>相关内容请参考<a href="https://github.com/apache/incubator-inlong/blob/master/CHANGES.md" target="_blank" rel="noopener noreferrer">版本说明</a>，其中详细列出了本次版本的特性、提升 和 Bug 修复，以及具体的贡献者。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="apache-inlongincubating-后续规划">Apache InLong(incubating) 后续规划<a href="#apache-inlongincubating-后续规划" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2><p>后续版本，我们将支持轻量化的 Sort，以及扩展更多的数据源端和目标端，覆盖更多的使用场景，主要包括：</p><ul><li>Flink SQL 支持</li><li>Elasticsearch、HBase 流向支持</li></ul>]]></content>
        <author>
            <name>dockerzhang</name>
            <uri>https://github.com/dockerzhang</uri>
        </author>
        <category label="Apache InLong" term="Apache InLong"/>
        <category label="Version" term="Version"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[0.12.0 版本发布]]></title>
        <id>https://inlong.apache.org/zh-CN/blog/2022/01/04/release-0.12.0</id>
        <link href="https://inlong.apache.org/zh-CN/blog/2022/01/04/release-0.12.0"/>
        <updated>2022-01-04T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[InLong(应龙) : 中国神话故事里的神兽，引流入海，借喻 InLong 系统提供数据接入能力。]]></summary>
        <content type="html"><![CDATA[<p>InLong(应龙) : 中国神话故事里的神兽，引流入海，借喻 InLong 系统提供数据接入能力。</p><p>Apache InLong（应龙）是一个一站式海量数据集成框架，提供自动、安全、可靠和高性能的数据传输能力，同时支持批和流，方便业务构建基于流式的数据分析、建模和应用。InLong支持大数据领域的采集、汇聚、缓存和分拣功能，用户只需要简单的配置就可以把数据从数据源导入到实时计算引擎或者落地到离线存储。</p><p>刚刚发布的 0.12.0-incubating 主要包括以下内容：</p><ul><li>提供自动、安全、可靠和高性能的数据传输能力，同时支持批和流</li><li>对官网文档结构进行重构，方便用户根据主线查阅相关文档</li><li>全流程支持Pulsar数据流向，完成高性能、高可靠场景的全流程覆盖</li><li>全流程支持指标，包括 JMX 和 Prometheus 输出</li><li>数据审计对账一期，将审计数据写入 MySQL</li></ul><p>该版本关闭了约 120+ 个 issue，包含四个重大 feature 和 35 个 improvements。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="apache-inlongincubating-简介">Apache InLong(incubating) 简介<a href="#apache-inlongincubating-简介" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p><a href="https://inlong.apache.org/zh-cn/" target="_blank" rel="noopener noreferrer">Apache InLong（应龙）</a> 是腾讯捐献给 Apache 社区的一站式海量数据集成框架，提供自动、安全、可靠和高性能的数据传输能力，方便业务构建基于流式的数据分析、建模和应用。 InLong 项目原名 TubeMQ ，专注于高性能、低成本的消息队列服务。为了进一步释放 TubeMQ 周边的生态能力，我们将项目升级为 InLong，专注打造一站式数据流接入服务平台。</p><p>Apache InLong 以腾讯内部使用的 TDBank 为原型，具有万亿级数据的接入和处理能力，整合了数据采集、汇聚、存储、分拣数据处理全流程，拥有简单易用、灵活扩展、稳定可靠等特性。</p><img loading="lazy" src="../img/inlong-structure-zh.png" align="center" alt="Apache InLong" class="img_ev3q"><p> Apache InLong 服务于数据采集到落地的整个生命周期，按数据的不同阶段提供不同的处理模块，主要包括：</p><ul><li><strong>inlong-agent</strong> ，数据采集 Agent ，支持从指定目录或文件读取常规日志，进行逐条的数据上报。后续也将扩展 DB 采集，扩展HTTP上报等能力。</li><li><strong>inlong-dataproxy</strong> ，一个基于 Flume-ng 的 Proxy 组件，支持数据发送阻塞、落盘重发，拥有将接收数据后转发到不同MQ（消息队列）的能力。</li><li><strong>inlong-tubemq</strong> ，腾讯自研的消息队列服务，专注服务大数据场景下海量数据的高性能存储和传输，在海量实践和低成本方面有着比较好的核心优势。</li><li><strong>inlong-sort</strong> ，从不同的 MQ 消费数据后进行 ETL 处理，然后将数据汇聚并写入 Hive、ClickHouse、Hbase、IceBerg 等。</li><li><strong>inlong-manager</strong> ，提供完整的数据服务管控能力，包括元数据、OpenAPI、任务流、权限等。</li><li><strong>inlong-website</strong> ，一个用于管理数据接入的前端页面，简化整个 InLong 管控平台的使用。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="apache-inlongincubating-0120-主要特性">Apache InLong(incubating) 0.12.0 主要特性<a href="#apache-inlongincubating-0120-主要特性" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-打通-apache-pulsar-全链路">1. 打通 Apache Pulsar 全链路<a href="#1-打通-apache-pulsar-全链路" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4><p>在 0.12.0 版本中，我们补齐了 FileAgent → DataProxy → Pulsar → Sort 的数据上报能力，至此，InLong 支持高性能和高可靠数据接入场景：相比高吞吐的 TubeMQ，Apache Pulsar能提供更好的数据一致性，更适用于金融、计费等对数据可靠性要求极高的场景。</p><img loading="lazy" src="/img/pulsar-arch-zh.png" align="center" alt="Report via Pulsar" class="img_ev3q"><p>感谢 @healchow、 @baomingyu、@leezng、@bruceneenhl、@ifndef-SleePy 等同学对这个特性的贡献，更多信息请参考，相关 PR 见 <a href="https://github.com/apache/incubator-inlong/issues/1310" target="_blank" rel="noopener noreferrer">INLONG-1310</a> ，使用指引见 <a href="https://inlong.apache.org/zh-CN/docs/next/quick_start/pulsar_example/" target="_blank" rel="noopener noreferrer">Pulsar使用示例</a> 。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-支持-jmx-和-prometheus-指标">2. 支持 JMX 和 Prometheus 指标<a href="#2-支持-jmx-和-prometheus-指标" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4><p>在已有的以文件输出指标之外，InLong 的各个组件开始逐步支持 JMX 和 Prometheus 指标的输出，以提升整个系统的可见性。目前包括 Agent，DataProxy，TubeMQ，Sort-Standalone 等模块已经支持上述指标，各个模块输出的指标的文档正在整理中。</p><p>感谢 @shink，@luchunliang，@EMsnap，@gosonzhang 等同学的贡献，相关 PR 见<a href="https://github.com/apache/incubator-inlong/issues/1712" target="_blank" rel="noopener noreferrer">INLONG-1712</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1786" target="_blank" rel="noopener noreferrer">INLONG-1786</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1796" target="_blank" rel="noopener noreferrer">INLONG-1796</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1827" target="_blank" rel="noopener noreferrer">INLONG-1827</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1851" target="_blank" rel="noopener noreferrer">INLONG-1851</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1926" target="_blank" rel="noopener noreferrer">INLONG-1926</a> 。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="3-模块能力扩充">3. 模块能力扩充<a href="#3-模块能力扩充" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4><p>Sort 模块增加了对 Apache Doris 存储的支持，实现了 Sort 分拣数据落地到 Apache Doris 的能力，使 InLong 的入库选择又多了一项。此外，为了丰富数据接入全流程的功能，增加了 Audit、Sort-Standalone 模块：</p><ul><li>Audit 模块提供数据流全流程的对账能力，通过数据流指标来监控系统的服务质量；</li><li>Sort-Standalone 模块是一个不基于 Flink 的数据分拣模块，给系统增加了一个轻量级的数据分拣能力，便于业务快速搭建及使用。</li></ul><p>Audit、Sort-Standalone 模块仍在开发中，版本稳定后将对外发布使用。</p><p>感谢 @huzk8，@doleyzi，@luchunliang 等同学的贡献，相关 PR 见 <a href="https://github.com/apache/incubator-inlong/issues/1821" target="_blank" rel="noopener noreferrer">INLONG-1821</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1738" target="_blank" rel="noopener noreferrer">INLONG-1738</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1889" target="_blank" rel="noopener noreferrer">INLONG-1889</a> 。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="4-官网文档目录重构">4. 官网文档目录重构<a href="#4-官网文档目录重构" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4><p>0.12.0 版本对功能模块的改进之外，官网结构以及使用文档方面也做了深度调整，包括重构文档的目录结构，补充完善各个模块的功能介绍，增加文档翻译，进一步提高 InLong 官网的文档可阅读性，实现快速查找、方便阅读。这块内容可以查看官网进行了解，目前文档还在持续建设中，欢迎大家提出宝贵的意见或建议。</p><p>感谢 @bluewang，@dockerzhang，@healchow 等同学的贡献，相关 PR 见 <a href="https://github.com/apache/incubator-inlong/issues/1711" target="_blank" rel="noopener noreferrer">INLONG-1711</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1740" target="_blank" rel="noopener noreferrer">INLONG-1740</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1802" target="_blank" rel="noopener noreferrer">INLONG-1802</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1809" target="_blank" rel="noopener noreferrer">INLONG-1809</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1810" target="_blank" rel="noopener noreferrer">INLONG-1810</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1815" target="_blank" rel="noopener noreferrer">INLONG-1815</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1822" target="_blank" rel="noopener noreferrer">INLONG-1822</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1840" target="_blank" rel="noopener noreferrer">INLONG-1840</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1856" target="_blank" rel="noopener noreferrer">INLONG-1856</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1861" target="_blank" rel="noopener noreferrer">INLONG-1861</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1867" target="_blank" rel="noopener noreferrer">INLONG-1867</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1878" target="_blank" rel="noopener noreferrer">INLONG-1878</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1901" target="_blank" rel="noopener noreferrer">INLONG-1901</a> ，<a href="https://github.com/apache/incubator-inlong/issues/1939" target="_blank" rel="noopener noreferrer">INLONG-1939</a> 。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="5-其他特性及问题修复">5. 其他特性及问题修复<a href="#5-其他特性及问题修复" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4><p>相关内容请参考<a href="https://github.com/apache/incubator-inlong/blob/0.12.0-incubating-RC0/CHANGES.md" target="_blank" rel="noopener noreferrer">版本发版说明</a> ，里面列出了本次版本详细的特性、改进，Bug 修复，以及具体的贡献者。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="apache-inlongincubating-后续规划">Apache InLong(incubating) 后续规划<a href="#apache-inlongincubating-后续规划" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>后续版本，我们会进一步释放 InLong 的能力，覆盖更多的使用场景，主要包括：</p><ul><li>支持数据接入 ClickHouse 的链路</li><li>支持 DB 数据的采集</li><li>全链路的指标审计二期功能</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="apache-inlongincubating-贡献者招募">Apache InLong(incubating) 贡献者招募<a href="#apache-inlongincubating-贡献者招募" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>Apache InLong(incubating) 当前共有 71 名 contributor，仍处在项目孵化的初期，还有很多待办事项，包括：Feature 开发、社区运营，文档翻译等，期待更多开源爱好者加入 InLong，一起将 InLong 打造成 Apache 顶级项目。以下为 InLong 项目的时间线：</p><ul><li>2021年12月22日，发布 0.12.0 版本</li><li>2021年11月5日，发布0.11.0版本</li><li>2021年9月3日，发布0.10.0版本</li><li>2021年7月12日，发起更名后第一个版本 0.9.0 投票</li><li>2021年4月11日，完成社区改名，调整为 Apache InLong</li><li>2021年2月11日，发起社区改名变更申请</li><li>2020年12月20日，进行项目改名讨论和投票</li><li>2020年5月30日，按照 Apache 社区规范发布第一个社区版本</li><li>2019年11月3日，进入 Apache 社区孵化</li><li>2019年9月12日，TubeMQ 对外开源并捐献给 Apache 社区</li></ul>]]></content>
        <author>
            <name>gosonzhang</name>
            <uri>https://github.com/gosonzhang</uri>
        </author>
        <category label="Apache InLong" term="Apache InLong"/>
        <category label="Version" term="Version"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[0.11.0 版本发布]]></title>
        <id>https://inlong.apache.org/zh-CN/blog/2021/11/10/release-0.11.0</id>
        <link href="https://inlong.apache.org/zh-CN/blog/2021/11/10/release-0.11.0"/>
        <updated>2021-11-10T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Apache InLong(incubating) 从 0.9.0 版本开始由原 Apache TubeMQ（incubating）改名而来，伴随着名称的改变，InLong 也由单一的消息队列升级为一站式海量数据集成框架，支持了大数据领域的采集、汇聚、缓存和分拣功能，用户只需要简单的配置就可以把数据从数据源导入到实时计算引擎或者落地到离线存储。]]></summary>
        <content type="html"><![CDATA[<p>Apache InLong(incubating) 从 0.9.0 版本开始由原 Apache TubeMQ（incubating）改名而来，伴随着名称的改变，InLong 也由单一的消息队列升级为一站式海量数据集成框架，支持了大数据领域的采集、汇聚、缓存和分拣功能，用户只需要简单的配置就可以把数据从数据源导入到实时计算引擎或者落地到离线存储。</p><p>刚刚发布的 0.11.0-incubating 版本是改名之后的第三个版本，这个版本：</p><ul><li>进一步降低用户的使用门槛，支持 InLong 所有模块 on Kubernets，并且对官网进行了重构，用户可以更加方便的查阅相关文档</li><li>支持更多的业务场景，增加 Dataproxy -&gt; Pulsar 的数据流向，覆盖对数据完整性、一致性要求更高的场景</li><li>支持更多语言的 SDK，这个版本开放了生产级别的 TubeMQ Go SDK，方便使用 Go 语言的用户接入</li></ul><p>该版本关闭超过 80 个 issue, 包含了四个重大 feature 和 35 个 improvements 。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="apache-inlongincubating-简介">Apache InLong(incubating) 简介<a href="#apache-inlongincubating-简介" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p><a href="https://inlong.apache.org/zh-cn/" target="_blank" rel="noopener noreferrer">Apache InLong（应龙）</a>是腾讯捐献给 Apache 社区的一站式海量数据集成框架，提供自动、安全、可靠和高性能的数据传输能力，方便业务构建基于流式的数据分析、建模和应用。InLong 项目原本叫TubeMQ ，专注高性能、低成本的消息队列服务。为了进一步释放 TubeMQ 周边生态能力，我们将项目升级为 InLong ，专注打造一站式的数据集成解决方案。</p><p>Apache InLong 以腾讯内部使用的 TDBank 为原型，依托万亿级别的数据接入和处理能力，整合了数据采集、汇聚、存储、分拣数据处理全流程，拥有简单易用、灵活扩展、稳定可靠等特性。</p><img loading="lazy" src="../img/inlong-structure-zh.png" align="center" alt="Apache InLong" class="img_ev3q"><p> Apache InLong 服务于数据采集到落地的整个生命周期，按数据的不同阶段提供不同的处理模块，主要包括：</p><ul><li><strong>inlong-agent</strong> ，数据采集 Agent ，支持从指定目录或文件读取常规日志，进行逐条的数据上报。后续也将扩展 DB 采集，扩展HTTP上报等能力。</li><li><strong>inlong-dataproxy</strong> ，一个基于 Flume-ng 的 Proxy 组件，支持数据发送阻塞、落盘重发，拥有将接收数据后转发到不同MQ（消息队列）的能力。</li><li><strong>inlong-tubemq</strong> ，腾讯自研的消息队列服务，专注服务大数据场景下海量数据的高性能存储和传输，在海量实践和低成本方面有着比较好的核心优势。 注：InLong 0.11.0 后台中增加了对于Apache Pulsar的支持，全流程数据流和管控工作会在下个版本完成。</li><li><strong>inlong-sort</strong> ，从不同的 MQ 消费数据后进行 ETL 处理，然后将数据汇聚并写入 Hive、ClickHouse、Hbase、IceBerg 等。</li><li><strong>inlong-manager</strong> ，提供完整的数据服务管控能力，包括元数据、OpenAPI、任务流、权限等。</li><li><strong>inlong-website</strong> ，一个用于管理数据接入的前端页面，简化整个 InLong 管控平台的使用。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="apache-inlongincubating-0110-主要特性">Apache InLong(incubating) 0.11.0 主要特性<a href="#apache-inlongincubating-0110-主要特性" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="inlong-on-kubernetes">InLong on Kubernetes<a href="#inlong-on-kubernetes" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4><p>InLong 包括了数据采集，数据汇聚，数据缓存、数据分拣以及集群管控等多个组件，为了方便用户使用和支持云原生特性，目前所有的组件都已经支持在 Kubernetes 部署。
感谢 @shink 贡献的这个特性，具体详情可以参考:
<a href="https://github.com/apache/incubator-inlong/issues/1308" target="_blank" rel="noopener noreferrer">INLONG-1308</a></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="dataproxy-pulsar-数据流打通">dataproxy-&gt;pulsar 数据流打通<a href="#dataproxy-pulsar-数据流打通" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4><p>在 0.11.0 版本之前的版本，InLong 的数据缓存层只能支持 TubeMQ，TubeMQ 很适合于超大规模数据量的场景，但在极端场景下可能会有少量数据丢失的风向；为了提供数据可靠性，Inlong 在 0.11.0 版本中增加了对于 Apache Pulsar 的支持，现在InLong 后台可以支持数据流可以从 agent -&gt; dataProxy -&gt; tubeMQ/pulsar -&gt; sort.  Pulsar 的引入，使得 InLong 覆盖的应用场景更加丰富，可以满足更多用户的需求。
感谢 @baomingyu 对于这个特性的贡献，更多详情可以参考:
<a href="https://github.com/apache/incubator-inlong/issues/1330" target="_blank" rel="noopener noreferrer">INLONG-1330</a></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="go-语言-sdk">Go 语言 SDK<a href="#go-语言-sdk" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4><p>在 0.11.0 版本之前的 TubeMQ 支持 Java 、C++、 Python 三种语言的 SDK，随着 Go 语言的应用越来越多，社区中对于 Go 语言 SDK 的需求也日益增加，0.11.0 版本正式引入了 TubeMQ 的 Go 语言 SDK。丰富了多语言 SDK，也降低了 Go 语言用户的接入和使用难度。
感谢 @TszKitLo40 贡献的这个特性，更多详情可以参考：
<a href="https://github.com/apache/incubator-inlong/issues/624" target="_blank" rel="noopener noreferrer">INLONG-624</a>
<a href="https://github.com/apache/incubator-inlong/issues/1570" target="_blank" rel="noopener noreferrer">INLONG-1578</a>
<a href="https://github.com/apache/incubator-inlong/issues/1584" target="_blank" rel="noopener noreferrer">INLONG-1584</a>
<a href="https://github.com/apache/incubator-inlong/issues/1666" target="_blank" rel="noopener noreferrer">INLONG-1666</a>
<a href="https://github.com/apache/incubator-inlong/issues/1682" target="_blank" rel="noopener noreferrer">INLONG-1682</a></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="官网重构">官网重构<a href="#官网重构" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4><p>在 0.11.0 版本中，InLong 采用 Docusaurus 重构了<a href="https://inlong.apache.org/" target="_blank" rel="noopener noreferrer">官网</a>，提供了更加简洁、直观的文档管理和展示。
感谢 @leezng 对于这个特性的贡献。更多详情可以参考：
<a href="https://github.com/apache/incubator-inlong/issues/1631" target="_blank" rel="noopener noreferrer">INLONG-1631</a>
<a href="https://github.com/apache/incubator-inlong/issues/1632" target="_blank" rel="noopener noreferrer">INLONG-1632</a>
<a href="https://github.com/apache/incubator-inlong/issues/1633" target="_blank" rel="noopener noreferrer">INLONG-1633</a>
<a href="https://github.com/apache/incubator-inlong/issues/1634" target="_blank" rel="noopener noreferrer">INLONG-1634</a>
<a href="https://github.com/apache/incubator-inlong/issues/1635" target="_blank" rel="noopener noreferrer">INLONG-1635</a>
<a href="https://github.com/apache/incubator-inlong/issues/1636" target="_blank" rel="noopener noreferrer">INLONG-1636</a>
<a href="https://github.com/apache/incubator-inlong/issues/1637" target="_blank" rel="noopener noreferrer">INLONG-1637</a>
<a href="https://github.com/apache/incubator-inlong/issues/1638" target="_blank" rel="noopener noreferrer">INLONG-1638</a></p><p>除了上述重大 feature 之外，InLong 0.11.0 版本还有其他的关键改进，包括但不限于：</p><ul><li>在主 Repo 中增加了贡献指引，<a href="https://github.com/apache/incubator-inlong/issues/1623" target="_blank" rel="noopener noreferrer">INLONG-1623</a></li><li>增加 Inlong-Manager 对 DataProxy 的配置管理，<a href="https://github.com/apache/incubator-inlong/issues/1595" target="_blank" rel="noopener noreferrer">INLONG-1595</a></li><li>优化了 github issue 模板，<a href="https://github.com/apache/incubator-inlong/issues/1585" target="_blank" rel="noopener noreferrer">INLONG-1585</a></li><li>代码 Checkstyle 优化，<a href="https://github.com/apache/incubator-inlong/issues/1571" target="_blank" rel="noopener noreferrer">INLONG-1571</a>, <a href="https://github.com/apache/incubator-inlong/issues/1593" target="_blank" rel="noopener noreferrer">INLONG-1593</a>, <a href="https://github.com/apache/incubator-inlong/issues/1593" target="_blank" rel="noopener noreferrer">INLONG-1593</a>, <a href="https://github.com/apache/incubator-inlong/issues/1662" target="_blank" rel="noopener noreferrer">INLONG-1662</a></li><li>Agent 引入消息过滤器，<a href="https://github.com/apache/incubator-inlong/issues/1641" target="_blank" rel="noopener noreferrer">INLONG-1641</a></li></ul><p>0.11.0 版本还修复了~45个bug，在此，感谢所有为 Inlong 社区做出贡献的各位同学（排名不分先后）
shink, baomingyu, TszKitLo40, leezng, ruanwenjun, leo65535, luchunliang, pierre94, EMsnap, dockerzhang, gosonzhang, healchow, guangxuCheng, yuanboliu</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="apache-inlongincubating-后续规划">Apache InLong(incubating) 后续规划<a href="#apache-inlongincubating-后续规划" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>在 InLong 后续版本规划中，我们会进一步释放 InLong 的能力，覆盖更多的使用场景，主要包括</p><ul><li>支持 Apache Pulsar 全链路数据接入能力，包括后端处理和前端管理能力。</li><li>支持 ClickHouse、Apache Iceberg、Apache HBase 等数据流向</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="apache-inlongincubating-贡献者招募">Apache InLong(incubating) 贡献者招募<a href="#apache-inlongincubating-贡献者招募" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3><p>Apache InLong(incubating) 当前的 contributor 共计62名，还处在项目孵化的初期，有很多工作需要做，包括社区运营、文档翻译、Feature 开发等，期待更多的开源爱好者一起共建，努力将 InLong 打造成 Apache 顶级项目，以下为 InLong 重要发展时间点：</p><ul><li>2021年11月5日，发布0.11.0版本</li><li>2021年9月3日，发布0.10.0版本</li><li>2021年7月12日，发起更名后第一个版本 0.9.0 投票</li><li>2021年4月11日，完成社区改名，调整为 Apache InLong</li><li>2021年2月11日，发起社区改名变更申请</li><li>2020年12月20日，进行项目改名讨论和投票</li><li>2020年5月30日，按照 Apache 社区规范发布第一个社区版本</li><li>2019年11月3日，进入 Apache 社区孵化</li><li>2019年9月12日，TubeMQ 对外开源并捐献给 Apache 社区</li></ul>]]></content>
        <author>
            <name>dockerzhang</name>
            <uri>https://github.com/dockerzhang</uri>
        </author>
        <category label="Apache InLong" term="Apache InLong"/>
        <category label="Version" term="Version"/>
    </entry>
</feed>